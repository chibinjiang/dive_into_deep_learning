{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jupyter 快捷方式\n",
    "- 进入 command mode\n",
    "    - esc\n",
    "    - a -> 向上插入cell\n",
    "    - b -> 向下插入cell\n",
    "    - m -> 切换成 markdown 模式\n",
    "    - y -> 切换成 python 代码模式\n",
    "    - d + d -> 删除 cell\n",
    "- 进入 edit mode\n",
    "    - enter -> 换行\n",
    "    - shift + enter -> 执行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 深度学习计算\n",
    "- 基于Block构造模型, 相较之前, 更加灵活:\n",
    "    - Block 可以是 Dense, 可以是layer, 可以是model\n",
    "- 方法:\n",
    "    - `__init__`, 创建模型参数\n",
    "    - `forward`: 定义前向计算\n",
    "    - `add`: 增加串联的Block子类实例\n",
    "    - `initialize`: 用uniform分布来初始化参数: `initialize(init, ctx, verbose, force_reinit)`\n",
    "    - mxnet会自动求梯度, 生成反向传播backward函数(厉害了)\n",
    "- ![计算图](http://zh.d2l.ai/_images/forward.svg)\n",
    "- 访问模型参数\n",
    "    - 访问 params属性: .params['dense0_weight']\n",
    "    - 直接使用点操作符: .weight, .bias\n",
    "- 延迟 初始化:\n",
    "    - 在initialize()时还没初始化, 毕竟 连 输入层的个数都不知道\n",
    "- 避免延后初始化(deferred initialization)\n",
    "    - 在声明层时, 指定输入的个数: `nn.Dense(num_outputs, in_units=input_units)`\n",
    "- 存储/读取参数:\n",
    "    - `Block.save_parameters`\n",
    "    - `Block.load_parameters`\n",
    "- 存储/读取ndarray:\n",
    "    - `nd.save`\n",
    "    - `nd.load`\n",
    "- GPU的context:\n",
    "   - `x_gpu = nd.array([1,2,3], ctx=mx.gpu(0))`\n",
    "   - `net.initialize(ctx=mx.gpu())`\n",
    "- 在 device之间传输数据:\n",
    "    - 深拷贝: copyto: `x.copyto(mx.gpu(0))`\n",
    "    - 浅拷贝: as_in_context: `x.as_in_context(mx,gpu(0))`\n",
    "        - 如果源变量和目标变量的context一致，as_in_context函数使目标变量和源变量共享源变量的内存或显存\n",
    "- \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import nd, init\n",
    "from mxnet.gluon import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Block):\n",
    "    \"\"\"\n",
    "    继承Block 构造模型\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MLP, self).__init__(**kwargs)\n",
    "        # 和 Sequential一样不需要定义输入层\n",
    "        self.hidden = nn.Dense(256, activation='relu')\n",
    "        self.output = nn.Dense(10)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.output(self.hidden(X)) ## 这样就点乘了???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = nd.random.uniform(shape=(2, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[0.52580893 0.04401636 0.14181727 0.53580195 0.31673068 0.4527305\n",
       "  0.6267065  0.3261177  0.7275436  0.30018947 0.02427271 0.26678815\n",
       "  0.430116   0.19952953 0.6521246  0.49263242 0.853246   0.34513777\n",
       "  0.47532478 0.33060053]\n",
       " [0.96920586 0.06620718 0.26563254 0.01386505 0.0135087  0.91165674\n",
       "  0.48375288 0.41375843 0.2561138  0.6770445  0.82371765 0.45239896\n",
       "  0.23277268 0.20063767 0.31062922 0.9294752  0.79122746 0.12266199\n",
       "  0.71514326 0.48137522]]\n",
       "<NDArray 2x20 @cpu(0)>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[-0.06070112 -0.07294163  0.04112982  0.0487619  -0.00259803 -0.04815025\n",
       "   0.04822326 -0.02091947 -0.0527753  -0.06360553]\n",
       " [-0.06579573 -0.11664213  0.02646019  0.06755988  0.06176336 -0.10675579\n",
       "   0.03999376 -0.01457253 -0.05268126 -0.08559721]]\n",
       "<NDArray 2x10 @cpu(0)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = MLP()\n",
    "net.initialize()\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySequencial(nn.Block):\n",
    "    \"\"\"\n",
    "    继承Block 构造Sequantial\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MySequencial, self).__init__(**kwargs)\n",
    "        \n",
    "    def add(self, *blocks):\n",
    "        \"\"\"\n",
    "        self._chidren 是一个 OrderedDict\n",
    "        \"\"\"\n",
    "        for block in blocks:\n",
    "            self._children[block.name] = block\n",
    "        \n",
    "    def forward(self, X):\n",
    "        for block in self._children.values():\n",
    "            X = block(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[-0.01626736  0.06074644  0.01985445 -0.01832244 -0.02094231  0.0452922\n",
       "   0.02652163 -0.07844356 -0.02887667  0.07291901]\n",
       " [-0.00768407  0.08003666  0.01333294  0.01722985 -0.06433114  0.03854203\n",
       "   0.05133884 -0.03060111 -0.02143979  0.04306421]]\n",
       "<NDArray 2x10 @cpu(0)>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_sequantial = MySequencial()\n",
    "my_sequantial.add(nn.Dense(256, activation='relu'), nn.Dense(10))\n",
    "my_sequantial.initialize()\n",
    "my_sequantial(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FancyMLP(nn.Block):\n",
    "    \"\"\"\n",
    "    定义复杂一点的网络\n",
    "    x = wx  ->  x = wx -> if |x| > 1: x/2; else: x*10\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(FancyMLP, self).__init__(**kwargs)\n",
    "        self.rand_weight = self.params.get_constant(\n",
    "            'rand_weight', nd.random.uniform(shape=(20, 20)))  # 使用get_constant创建的参数是常量参数, 不会在训练中迭代\n",
    "        self.dense = nn.Dense(20, activation=\"relu\")\n",
    "        print(\"__init__: \", self.dense)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        print(\"Initialize: \", X)\n",
    "        X = self.dense(X)\n",
    "        print(\"First dense: \", X)\n",
    "        X = nd.relu(nd.dot(X, self.rand_weight.data()) + 1)\n",
    "        print(\"RELU and dot: \", X)\n",
    "        X = self.dense(X)  # 复用全连接层, 参数共享\n",
    "        print(\"Second dense: \", X, X.norm(), X.norm().asscalar())\n",
    "        while X.norm() > 1: # .asscalar() > 1:\n",
    "            print(\"大于1: \", X.norm().asscalar())\n",
    "            X /= 2\n",
    "        if X.norm() < 0.8:  # .asscalar() < 0.8:\n",
    "            print(\"小于 0.8: \", X.norm().asscalar())\n",
    "            X *= 10\n",
    "        return X.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__:  Dense(None -> 20, Activation(relu))\n",
      "Initialize:  \n",
      "[[0.52580893 0.04401636 0.14181727 0.53580195 0.31673068 0.4527305\n",
      "  0.6267065  0.3261177  0.7275436  0.30018947 0.02427271 0.26678815\n",
      "  0.430116   0.19952953 0.6521246  0.49263242 0.853246   0.34513777\n",
      "  0.47532478 0.33060053]\n",
      " [0.96920586 0.06620718 0.26563254 0.01386505 0.0135087  0.91165674\n",
      "  0.48375288 0.41375843 0.2561138  0.6770445  0.82371765 0.45239896\n",
      "  0.23277268 0.20063767 0.31062922 0.9294752  0.79122746 0.12266199\n",
      "  0.71514326 0.48137522]]\n",
      "<NDArray 2x20 @cpu(0)>\n",
      "First dense:  \n",
      "[[0.07024643 0.         0.06379425 0.         0.09142933 0.\n",
      "  0.         0.         0.01337921 0.00755521 0.00864871 0.\n",
      "  0.         0.03104995 0.         0.09223591 0.16523626 0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.1921282  0.03930675 0.12466463 0.00540278\n",
      "  0.         0.         0.02709076 0.02961882 0.         0.\n",
      "  0.         0.         0.         0.09034698 0.22440496 0.\n",
      "  0.         0.        ]]\n",
      "<NDArray 2x20 @cpu(0)>\n",
      "RELU and dot:  \n",
      "[[1.3010497 1.3505931 1.2595625 1.2025903 1.3299769 1.303037  1.1982055\n",
      "  1.1423217 1.3166078 1.3873401 1.2023572 1.3274838 1.2546005 1.305752\n",
      "  1.3177594 1.2864249 1.3768247 1.137123  1.2107162 1.3365853]\n",
      " [1.4641263 1.4180241 1.339287  1.2862799 1.5104661 1.4544479 1.3263142\n",
      "  1.1773075 1.3953531 1.5426271 1.2994766 1.4349976 1.3814965 1.4762635\n",
      "  1.4441762 1.3504012 1.4313169 1.249779  1.2948576 1.3758512]]\n",
      "<NDArray 2x20 @cpu(0)>\n",
      "Second dense:  \n",
      "[[0.01688171 0.         0.43586293 0.         0.2988405  0.10474561\n",
      "  0.         0.         0.         0.11997521 0.06477702 0.\n",
      "  0.         0.0978228  0.         0.2431545  0.49365312 0.\n",
      "  0.         0.        ]\n",
      " [0.02333189 0.         0.4868759  0.         0.317801   0.12019583\n",
      "  0.         0.         0.         0.13835202 0.07184868 0.\n",
      "  0.         0.10066601 0.         0.25130463 0.53860116 0.\n",
      "  0.         0.        ]]\n",
      "<NDArray 2x20 @cpu(0)> \n",
      "[1.1671482]\n",
      "<NDArray 1 @cpu(0)> 1.1671482\n",
      "大于1:  1.1671482\n",
      "小于 0.8:  0.5835741\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "[19.623453]\n",
       "<NDArray 1 @cpu(0)>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fancy_mlp = FancyMLP()\n",
    "fancy_mlp.initialize()\n",
    "fancy_mlp(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NestMLP(nn.Block):\n",
    "    \"\"\"\n",
    "    嵌套调用 Block子类 和 Sequential\n",
    "    输入: X_m*n\n",
    "    X_m*n * W1_n*64 -(relu)-> H1_m*64 * W2_64*32 -(relu)-> O1_m*32 * W3_32*16 -(relu)-> O2_m*16\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(NestMLP, self).__init__(**kwargs)\n",
    "        self.net = nn.Sequential()\n",
    "        self.net.add(nn.Dense(64, activation='relu'), nn.Dense(32, activation='relu'))\n",
    "        self.dense = nn.Dense(16, activation='relu')\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.dense(self.net(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[0.         0.00068155 0.00380999 0.00216276 0.00086105 0.\n",
       "  0.         0.00184968 0.00136407 0.         0.         0.\n",
       "  0.         0.00276379 0.00014916 0.        ]\n",
       " [0.         0.0021382  0.00417513 0.00222392 0.00198193 0.\n",
       "  0.         0.0026347  0.         0.         0.         0.\n",
       "  0.         0.00541991 0.00186445 0.        ]]\n",
       "<NDArray 2x16 @cpu(0)>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nest_mlp = NestMLP()\n",
    "nest_mlp.initialize()\n",
    "nest_mlp(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__:  Dense(None -> 20, Activation(relu))\n",
      "Initialize:  \n",
      "[[-1.3215184e-04  1.6501137e-04  3.3890214e-04  3.0373316e-04\n",
      "   2.7971971e-04  4.4500313e-04 -3.1594638e-04  1.8301987e-04\n",
      "   3.2636931e-04 -9.0669550e-05  6.0050341e-05  1.3032819e-04\n",
      "  -3.4925487e-04  1.7909531e-04  1.9252884e-04 -1.5353228e-04\n",
      "  -2.9035352e-04  6.0592662e-04  2.0440918e-04 -3.2938588e-05]\n",
      " [-1.6919333e-04  2.8088191e-04  3.5906580e-04  2.7008241e-04\n",
      "   1.1220090e-04  5.9315155e-04 -1.9164746e-04  1.2763157e-04\n",
      "   4.2085416e-04 -1.8352392e-04  8.0380181e-05 -3.2929376e-05\n",
      "  -2.5981246e-04  1.0404169e-04  2.6852544e-04  2.5695845e-05\n",
      "  -3.7983494e-04  6.2260020e-04 -9.8600703e-06 -4.3311229e-05]]\n",
      "<NDArray 2x20 @cpu(0)>\n",
      "First dense:  \n",
      "[[1.3807738e-05 1.1303832e-05 1.6630645e-04 0.0000000e+00 3.6790429e-05\n",
      "  0.0000000e+00 5.3354311e-06 7.2666131e-05 8.4236824e-05 0.0000000e+00\n",
      "  3.9687871e-05 0.0000000e+00 0.0000000e+00 0.0000000e+00 4.2794942e-05\n",
      "  0.0000000e+00 0.0000000e+00 3.0408901e-05 0.0000000e+00 0.0000000e+00]\n",
      " [1.9604735e-05 1.4539186e-05 1.5092839e-04 0.0000000e+00 5.0852006e-05\n",
      "  0.0000000e+00 0.0000000e+00 7.9355705e-05 7.8385485e-05 0.0000000e+00\n",
      "  6.5022068e-05 0.0000000e+00 0.0000000e+00 0.0000000e+00 3.5249781e-05\n",
      "  9.8745932e-06 0.0000000e+00 3.0882366e-05 0.0000000e+00 0.0000000e+00]]\n",
      "<NDArray 2x20 @cpu(0)>\n",
      "RELU and dot:  \n",
      "[[1.0003554 1.0001565 1.0002508 1.0002241 1.0003294 1.0001829 1.0002393\n",
      "  1.0002569 1.0003449 1.0003119 1.000314  1.0002408 1.0002003 1.0003337\n",
      "  1.0001944 1.0002416 1.0002775 1.0002147 1.0002108 1.0001585]\n",
      " [1.0003737 1.0001892 1.0002872 1.0002308 1.0003403 1.0001925 1.000258\n",
      "  1.0002575 1.0003569 1.0003383 1.0003406 1.0002632 1.0002205 1.000337\n",
      "  1.000199  1.000253  1.0003159 1.0002311 1.00023   1.0001613]]\n",
      "<NDArray 2x20 @cpu(0)>\n",
      "Second dense:  \n",
      "[[0.         0.08097166 0.21232921 0.23539107 0.06410087 0.5852261\n",
      "  0.         0.04655921 0.         0.12643522 0.         0.\n",
      "  0.         0.         0.08520652 0.         0.01976224 0.30322534\n",
      "  0.         0.        ]\n",
      " [0.         0.0809717  0.21233101 0.23539636 0.0641021  0.58523613\n",
      "  0.         0.04655667 0.         0.126438   0.         0.\n",
      "  0.         0.         0.08521096 0.         0.01976312 0.30323315\n",
      "  0.         0.        ]]\n",
      "<NDArray 2x20 @cpu(0)>\n",
      "大于1:  1.0690259\n",
      "小于 0.8:  0.53451294\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "[17.592234]\n",
       "<NDArray 1 @cpu(0)>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nest_seq = nn.Sequential()\n",
    "nest_seq.add(NestMLP(), nn.Dense(20), FancyMLP())\n",
    "nest_seq.initialize()\n",
    "nest_seq(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[0.52580893 0.04401636 0.14181727 0.53580195 0.31673068 0.4527305\n",
       "  0.6267065  0.3261177  0.7275436  0.30018947 0.02427271 0.26678815\n",
       "  0.430116   0.19952953 0.6521246  0.49263242 0.853246   0.34513777\n",
       "  0.47532478 0.33060053]\n",
       " [0.96920586 0.06620718 0.26563254 0.01386505 0.0135087  0.91165674\n",
       "  0.48375288 0.41375843 0.2561138  0.6770445  0.82371765 0.45239896\n",
       "  0.23277268 0.20063767 0.31062922 0.9294752  0.79122746 0.12266199\n",
       "  0.71514326 0.48137522]]\n",
       "<NDArray 2x20 @cpu(0)>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X # 并没有改变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ErrorMLP(nn.Block):\n",
    "    \"\"\"\n",
    "    继承Block 构造模型\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        # 和 Sequential一样不需要定义输入层\n",
    "        self.hidden = nn.Dense(256, activation='relu')\n",
    "        self.output = nn.Dense(10)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.output(self.hidden(X)) ## 这样就点乘了???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ErrorMLP' object has no attribute '_children'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-38ded96684dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mErrorMLP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-54-5f53c309fce6>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;31m# 和 Sequential一样不需要定义输入层\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Learning/EnvLearning/lib/python3.7/site-packages/mxnet/gluon/block.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBlock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reg_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Learning/EnvLearning/lib/python3.7/site-packages/mxnet/gluon/block.py\u001b[0m in \u001b[0;36mregister_child\u001b[0;34m(self, block, name)\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m             \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_children\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_children\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_forward_pre_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ErrorMLP' object has no attribute '_children'"
     ]
    }
   ],
   "source": [
    "mlp = ErrorMLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ErrorNestMLP(nn.Block):\n",
    "    \"\"\"\n",
    "    嵌套调用 Block子类 和 Sequential\n",
    "    输入: X_m*n\n",
    "    X_m*n * W1_n*64 -(relu)-> H1_m*64 * W2_64*32 -(relu)-> O1_m*32 * W3_32*16 -(relu)-> O2_m*16\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ErrorNestMLP, self).__init__(**kwargs)\n",
    "        # 用 list 代替 Sequential()\n",
    "        self.net = [nn.Dense(64, activation='relu'), nn.Dense(32, activation='relu')]\n",
    "        self.dense = nn.Dense(16, activation='relu')\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.dense(self.net(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhibin.jiang/Learning/EnvLearning/lib/python3.7/site-packages/mxnet/gluon/block.py:510: UserWarning: \"ErrorNestMLP.net\" is an unregistered container with Blocks. Note that Blocks inside the list, tuple or dict will not be registered automatically. Make sure to register them using register_child() or switching to nn.Sequential/nn.HybridSequential instead. \n",
      "  self.collect_params().initialize(init, ctx, verbose, force_reinit)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'list' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-aa2a290441e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0merror_nest_mlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mErrorNestMLP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0merror_nest_mlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0merror_nest_mlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Learning/EnvLearning/lib/python3.7/site-packages/mxnet/gluon/block.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    546\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-72-3641d8b83395>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'list' object is not callable"
     ]
    }
   ],
   "source": [
    "error_nest_mlp = ErrorNestMLP()\n",
    "error_nest_mlp.initialize()\n",
    "error_nest_mlp(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "失败\n"
     ]
    }
   ],
   "source": [
    "print(\"胜利\" if X.norm() < 1 else \"失败\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[3.2021255]\n",
      "<NDArray 1 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "print(X.norm())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultipleDenses(nn.Block):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MultipleDenses, self).__init__(**kwargs)\n",
    "        # wrong\n",
    "        self.denses = [nn.Dense(64, activation='relu'), nn.Dense(32, activation='relu'), nn.Dense(16, activation='relu')]\n",
    "    \n",
    "    def forward(self, X):\n",
    "        for dense in self.denses:\n",
    "            X = dense(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Parameter 'dense61_weight' has not been initialized. Note that you should initialize parameters and create Trainer with Block.collect_params() instead of Block.params because the later does not include Parameters of nested child Blocks",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-fc037702752d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmultiple_dense\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultipleDenses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmultiple_dense\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmultiple_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Learning/EnvLearning/lib/python3.7/site-packages/mxnet/gluon/block.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    546\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-79-47605a42aa1c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdense\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdenses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Learning/EnvLearning/lib/python3.7/site-packages/mxnet/gluon/block.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    546\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Learning/EnvLearning/lib/python3.7/site-packages/mxnet/gluon/block.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m                     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reg_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mDeferredInitializationError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deferred_infer_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Learning/EnvLearning/lib/python3.7/site-packages/mxnet/gluon/block.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m                     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reg_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mDeferredInitializationError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deferred_infer_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Learning/EnvLearning/lib/python3.7/site-packages/mxnet/gluon/parameter.py\u001b[0m in \u001b[0;36mdata\u001b[0;34m(self, ctx)\u001b[0m\n\u001b[1;32m    541\u001b[0m                                \u001b[0;34m\"because its storage type is %s. Please use row_sparse_data() \"\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m                                \"instead.\" % (self.name, str(ctx), self._stype))\n\u001b[0;32m--> 543\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_and_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlist_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Learning/EnvLearning/lib/python3.7/site-packages/mxnet/gluon/parameter.py\u001b[0m in \u001b[0;36m_check_and_get\u001b[0;34m(self, arr_list, ctx)\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0;34m\"with Block.collect_params() instead of Block.params \"\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0;34m\"because the later does not include Parameters of \"\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m             \"nested child Blocks\"%(self.name))\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_row_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Parameter 'dense61_weight' has not been initialized. Note that you should initialize parameters and create Trainer with Block.collect_params() instead of Block.params because the later does not include Parameters of nested child Blocks"
     ]
    }
   ],
   "source": [
    "multiple_dense = MultipleDenses()\n",
    "multiple_dense.initialize()\n",
    "multiple_dense(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential()\n",
    "net.add(nn.Dense(256, activation='relu'))\n",
    "net.add(nn.Dense(10))\n",
    "net.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "DeferredInitializationError",
     "evalue": "Parameter 'dense64_weight' has not been initialized yet because initialization was deferred. Actual initialization happens during the first forward pass. Please pass one batch of data through the network before accessing Parameters. You can also avoid deferred initialization by specifying in_units, num_features, etc., for network layers.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDeferredInitializationError\u001b[0m               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-59ea5453a5fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Learning/EnvLearning/lib/python3.7/site-packages/mxnet/gluon/parameter.py\u001b[0m in \u001b[0;36mdata\u001b[0;34m(self, ctx)\u001b[0m\n\u001b[1;32m    541\u001b[0m                                \u001b[0;34m\"because its storage type is %s. Please use row_sparse_data() \"\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m                                \"instead.\" % (self.name, str(ctx), self._stype))\n\u001b[0;32m--> 543\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_and_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlist_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Learning/EnvLearning/lib/python3.7/site-packages/mxnet/gluon/parameter.py\u001b[0m in \u001b[0;36m_check_and_get\u001b[0;34m(self, arr_list, ctx)\u001b[0m\n\u001b[1;32m    232\u001b[0m                 \u001b[0;34m\"Please pass one batch of data through the network before accessing Parameters. \"\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                 \u001b[0;34m\"You can also avoid deferred initialization by specifying in_units, \"\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                 \"num_features, etc., for network layers.\"%(self.name))\n\u001b[0m\u001b[1;32m    235\u001b[0m         raise RuntimeError(\n\u001b[1;32m    236\u001b[0m             \u001b[0;34m\"Parameter '%s' has not been initialized. Note that \"\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDeferredInitializationError\u001b[0m: Parameter 'dense64_weight' has not been initialized yet because initialization was deferred. Actual initialization happens during the first forward pass. Please pass one batch of data through the network before accessing Parameters. You can also avoid deferred initialization by specifying in_units, num_features, etc., for network layers."
     ]
    }
   ],
   "source": [
    "net[0].weight.data()  # 在进行前向计算前才会 初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dense64_ (\n",
       "  Parameter dense64_weight (shape=(256, 20), dtype=float32)\n",
       "  Parameter dense64_bias (shape=(256,), dtype=float32)\n",
       ")"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[1. 1. 1. ... 1. 1. 1.]\n",
       " [1. 1. 1. ... 1. 1. 1.]\n",
       " [1. 1. 1. ... 1. 1. 1.]\n",
       " ...\n",
       " [1. 1. 1. ... 1. 1. 1.]\n",
       " [1. 1. 1. ... 1. 1. 1.]\n",
       " [1. 1. 1. ... 1. 1. 1.]]\n",
       "<NDArray 256x20 @cpu(0)>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].params['dense64_weight'].data() == net[0].weight.data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
       " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
       "<NDArray 256 @cpu(0)>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].params['dense64_bias'].data() == net[0].bias.data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
       " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
       "<NDArray 256 @cpu(0)>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].bias.data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[0. 0. 0. ... 0. 0. 0.]\n",
       " [0. 0. 0. ... 0. 0. 0.]\n",
       " [0. 0. 0. ... 0. 0. 0.]\n",
       " ...\n",
       " [0. 0. 0. ... 0. 0. 0.]\n",
       " [0. 0. 0. ... 0. 0. 0.]\n",
       " [0. 0. 0. ... 0. 0. 0.]]\n",
       "<NDArray 256x20 @cpu(0)>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 求梯度: 在反向计算前, 梯度值都是0\n",
    "net[0].weight.grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequential11_ (\n",
      "  Parameter dense64_weight (shape=(256, 20), dtype=float32)\n",
      "  Parameter dense64_bias (shape=(256,), dtype=float32)\n",
      "  Parameter dense65_weight (shape=(10, 256), dtype=float32)\n",
      "  Parameter dense65_bias (shape=(10,), dtype=float32)\n",
      ")\n",
      "sequential11_ (\n",
      "  Parameter dense64_weight (shape=(256, 20), dtype=float32)\n",
      "  Parameter dense65_weight (shape=(10, 256), dtype=float32)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# collect_params, 通过正则匹配参数\n",
    "print(net.collect_params())\n",
    "print(net.collect_params(\".*weight\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 2.0388728e-03  5.0904877e-03  1.9365953e-03 ... -7.9620769e-03\n",
       "  -2.0083881e-03 -8.2816696e-03]\n",
       " [-3.2664095e-03  3.5921552e-03  2.9730289e-03 ...  3.8690998e-03\n",
       "   4.8305974e-03 -3.5797848e-04]\n",
       " [ 4.0084305e-03  6.6222262e-04  1.1165363e-02 ... -4.2826491e-03\n",
       "   6.1445148e-03 -1.5364649e-03]\n",
       " ...\n",
       " [-2.4511721e-02 -1.0328277e-02 -6.6571822e-03 ... -8.2627647e-03\n",
       "  -5.4091369e-03 -7.8883460e-03]\n",
       " [ 1.4808148e-02 -8.1008542e-03 -1.3116258e-04 ...  1.0994526e-03\n",
       "   1.5791535e-02  4.4286947e-04]\n",
       " [ 7.0945927e-05 -5.7791389e-04 -1.2423999e-03 ...  1.0772002e-02\n",
       "   1.2763192e-02  2.5891021e-03]]\n",
       "<NDArray 256x20 @cpu(0)>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 强制初始化模型参数, force reinit\n",
    "net.initialize(init=init.Normal(sigma=0.01), force_reinit=True)\n",
    "net[0].weight.data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[1. 1. 1. ... 1. 1. 1.]\n",
       " [1. 1. 1. ... 1. 1. 1.]\n",
       " [1. 1. 1. ... 1. 1. 1.]\n",
       " ...\n",
       " [1. 1. 1. ... 1. 1. 1.]\n",
       " [1. 1. 1. ... 1. 1. 1.]\n",
       " [1. 1. 1. ... 1. 1. 1.]]\n",
       "<NDArray 256x20 @cpu(0)>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用常量初始化参数\n",
    "net.initialize(init.Constant(1), force_reinit=True)\n",
    "net[0].weight.data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init dense64_weight (256, 20)\n",
      "Init dense65_weight (10, 256)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "[ 0.         0.         9.494465  -0.         0.         0.\n",
       "  0.        -0.         9.339119  -0.        -0.        -7.1404243\n",
       " -0.        -0.        -9.122751   0.        -6.3159137  0.\n",
       " -5.2562075  0.       ]\n",
       "<NDArray 20 @cpu(0)>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 自定义初始化方法\n",
    "class MyInit(init.Initializer):\n",
    "    def _init_weight(self, name, data):\n",
    "        print('Init', name, data.shape)\n",
    "        data[:] = nd.random.uniform(low=-10, high=10, shape=data.shape)\n",
    "        data *= data.abs() >= 5\n",
    "\n",
    "net.initialize(MyInit(), force_reinit=True)\n",
    "net[0].weight.data()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 2.         2.        11.494465  ...  2.        -3.2562075  2.       ]\n",
       " [-4.3299108  2.         7.0956774 ...  2.        -7.4145813 -6.4642754]\n",
       " [ 2.         2.        10.1654625 ...  2.         2.         8.529558 ]\n",
       " ...\n",
       " [-6.5428123 -3.6284614  2.        ...  2.         2.         7.1772413]\n",
       " [-4.460295   8.433802   8.040327  ...  2.         2.         2.       ]\n",
       " [11.683821   9.593361   2.        ...  2.        -7.5182877 10.365871 ]]\n",
       "<NDArray 256x20 @cpu(0)>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用 set_data 改写 模型参数\n",
    "net[0].weight.set_data(net[0].weight.data() + 1)\n",
    "net[0].weight.data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[1. 1. 1. 1. 1. 1. 1. 1.]\n",
       "<NDArray 8 @cpu(0)>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 共享模型参数\n",
    "net = nn.Sequential()\n",
    "shared = nn.Dense(8, activation='relu')\n",
    "net.add(nn.Dense(8, activation='relu'),\n",
    "        shared,  # 在构造第三隐藏层时通过params来指定它使用第二隐藏层的参数\n",
    "        nn.Dense(8, activation='relu', params=shared.params),\n",
    "        nn.Dense(10))\n",
    "net.initialize()\n",
    "\n",
    "X = nd.random.uniform(shape=(2, 20))\n",
    "net(X)\n",
    "\n",
    "net[1].weight.data()[0] == net[2].weight.data()[0]\n",
    "# 第二隐藏层和第三隐藏层的参数 的维度必须一样\n",
    "# 模型参数里包含了梯度，所以在反向传播计算时，第二隐藏层和第三隐藏层的梯度都会被累加在shared.params.grad()里"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 练习\n",
    "1. 如果不在Block子类的 __init__中调用父类的__init__, 会报什么错? \n",
    "    - 子类不能继承父类的属性, 导致: `AttributeError: 'ErrorMLP' object has no attribute '_children'`\n",
    "2. 如果去掉FancyMLP类里面的asscalar函数，会有什么问题？\n",
    "    - 应该没什么问题\n",
    "    - 向量不能判断其布尔值: ValueError: The truth value of an NDArray with multiple elements is ambiguous.\n",
    "3. 如果将NestMLP类中通过Sequential实例定义的self.net改为self.net = [nn.Dense(64, activation='relu'), nn.Dense(32, activation='relu')]，会有什么问题？\n",
    "    - TypeError: 'list' object is not callable\n",
    "4. 当你要在__init__中定义Dense的列表时, 推荐 使用Sequential(), 而 [self.dense1, self.dense2] 这种方式次之\n",
    "    - 否则直接列表会报错: RuntimeError: Parameter 'dense61_weight' has not been initialized. Note that you should initialize parameters and create Trainer with Block.collect_params() instead of Block.params because the later does not include Parameters of nested child Blocks\n",
    "    - 原因: type是list的对象不会被注册到 Block._children属性中, 导致initialize()时找不到神经元\n",
    "5. 构造一个含共享参数层的多层感知机并训练。在训练过程中，观察每一层的模型参数和梯度\n",
    "    - 为什么要共享参数, 节省空间和计算量 ??\n",
    "    - 参数共享在后面应该会用到"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
