{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write code in MXnet/Gluon/Numpy  \n",
    "今天开始入坑了  [中文社区](https://discuss.gluon.ai), [英文社区](https://discuss.mxnet.io)    \n",
    "\n",
    "### 大纲\n",
    "#### lecture 1: 背景\n",
    "#### lecture 2: 预备知识\n",
    "#### lecture 3: 基础概念和技术\n",
    "#### lecture 4: 重要组成部分\n",
    "#### lecture 5: 卷积网络\n",
    "#### lecture 6: 处理序列数据的循环神经网络\n",
    "#### lecture 7: 优化算法\n",
    "#### lecture 8: 检查性能\n",
    "#### lecture 9: 计算机视觉\n",
    "#### lecture 10: 自然语言处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 逆向思考: 与其设计一个解决问题的程序，不如从最终的需求入手来寻找一个解决方案\n",
    "2. 英语单词:  \n",
    "    - exemplar: 模范\n",
    "    - practitioners: 从业者\n",
    "    - Realize: 实现\n",
    "    - simultaneously: 同时\n",
    "    - motivations: 动机\n",
    "    - pitfalls: 陷阱\n",
    "    - navigate: 导航\n",
    "    - get the most out of: 充分利用\n",
    "    - formidable: 艰巨的\n",
    "    - unified: 统一的\n",
    "    - would-be: 未来的, 即将成为的\n",
    "    - sporadic: 零星的\n",
    "    - elude: 躲避\n",
    "    - huddle: 挤在\n",
    "    - ponder: 思考\n",
    "    - encapsulate: 封装\n",
    "3. 应用DL 要求明白:\n",
    "    - 转换问题的动机\n",
    "    - 其中的数学\n",
    "    - 优化算法, 让模型更适应数据\n",
    "    - 有效训练模型的工程\n",
    "4. 我的困惑, 也是此书的目的之一: 市面上大部分教材都是关注于 how to implement a given approach, 却忽视 why certain algorithmic decisions are made? 因为我需要: \n",
    "    - the concepts behind deep learning\n",
    "    - realizations of the concepts in code\n",
    "5. 网站:\n",
    "    - jupyter, 融合code/公式/文本\n",
    "    - sphinx: 生成code/latex的输出\n",
    "    - Discourse: 论坛\n",
    "6. 你在生活中有没有这样的场景：虽有许多展示如何解决问题的样例，但缺少自动解决问题的算法？它们也许是深度学习的最好猎物\n",
    "7. mxnet的NDArray比numpy的ndarray提供GPU计算和自动求梯度\n",
    "8. broadcasting: 当形状不同的ndarray按元素运算时, 会先复制元素让两个ndarray形状相同\n",
    "9. 节省内存开销: `[:]`, `X[:] = X + Y` 或者 `X += Y `\n",
    "10. mxnet的ndarray和 numpy的ndarray转换: \n",
    "    - `nd.array(np_array)`\n",
    "    - `nd.array().asnumpy()`\n",
    "11. 自动求导数/梯度(gradient)\n",
    "12. 随机数的生成方法(`nd.random`):\n",
    "    - normal, 正态分布\n",
    "    - uniform, 均匀分布\n",
    "    - poisson, 泊松分布\n",
    "13. [如何使用jupyter编写数学公式(译)](https://www.jianshu.com/p/93ccc63e5a1b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = nd.arange(12)\n",
    "X = x.reshape((3,4))\n",
    "Y = nd.array([[2, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 1.1630787   0.4838046   0.29956347  0.15302546]\n",
       " [-1.1688148   1.5580711  -0.5459446  -2.3556297 ]\n",
       " [ 0.5414402   2.6785066   1.2546344  -0.54877394]]\n",
       "<NDArray 3x4 @cpu(0)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nd.random.normal(0, 1, shape=(3, 4))  # 每个元素都随机采样于均值为0、标准差为1的正态分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 2.  2.  6.  6.]\n",
       " [ 5.  7.  9. 11.]\n",
       " [12. 12. 12. 12.]]\n",
       "<NDArray 3x4 @cpu(0)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X + Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 2.  2.  6.  6.]\n",
       " [ 5.  7.  9. 11.]\n",
       " [12. 12. 12. 12.]]\n",
       "<NDArray 3x4 @cpu(0)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nd.elemwise_add(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 2.  2.  6.  6.]\n",
       " [ 5.  7.  9. 11.]\n",
       " [12. 12. 12. 12.]]\n",
       "<NDArray 3x4 @cpu(0)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z = Y.zeros_like()\n",
    "nd.elemwise_add(X, Y, out=Z)\n",
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 0.  1.  8.  9.]\n",
       " [ 4. 10. 18. 28.]\n",
       " [32. 27. 20. 11.]]\n",
       "<NDArray 3x4 @cpu(0)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X * Y  # element-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 0.    1.    0.5   1.  ]\n",
       " [ 4.    2.5   2.    1.75]\n",
       " [ 2.    3.    5.   11.  ]]\n",
       "<NDArray 3x4 @cpu(0)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X / Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 7.389056   2.7182817 54.59815   20.085537 ]\n",
       " [ 2.7182817  7.389056  20.085537  54.59815  ]\n",
       " [54.59815   20.085537   7.389056   2.7182817]]\n",
       "<NDArray 3x4 @cpu(0)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 0.  1.  2.  3.]\n",
       " [ 4.  5.  6.  7.]\n",
       " [ 8.  9. 10. 11.]\n",
       " [ 2.  1.  4.  3.]\n",
       " [ 1.  2.  3.  4.]\n",
       " [ 4.  3.  2.  1.]]\n",
       "<NDArray 6x4 @cpu(0)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nd.concat(X, Y, dim=0)  # 纵向连结"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 0.  1.  2.  3.  2.  1.  4.  3.]\n",
       " [ 4.  5.  6.  7.  1.  2.  3.  4.]\n",
       " [ 8.  9. 10. 11.  4.  3.  2.  1.]]\n",
       "<NDArray 3x8 @cpu(0)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nd.concat(X, Y, dim=1)  # 横向连结"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 18.  20.  10.]\n",
       " [ 58.  60.  50.]\n",
       " [ 98. 100.  90.]]\n",
       "<NDArray 3x3 @cpu(0)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nd.dot(X, Y.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[0. 1. 0. 1.]\n",
       " [0. 0. 0. 0.]\n",
       " [0. 0. 0. 0.]]\n",
       "<NDArray 3x4 @cpu(0)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X == Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[0. 0. 0. 0.]\n",
       " [1. 1. 1. 1.]\n",
       " [1. 1. 1. 1.]]\n",
       "<NDArray 3x4 @cpu(0)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X > Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[1. 0. 1. 0.]\n",
       " [0. 0. 0. 0.]\n",
       " [0. 0. 0. 0.]]\n",
       "<NDArray 3x4 @cpu(0)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X < Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[66.]\n",
       "<NDArray 1 @cpu(0)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[22.494442]\n",
       "<NDArray 1 @cpu(0)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.norm()  # L2 范数: 所有元素的平方和的开方"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.494442"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.norm().asscalar()  # 将结果转为标量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自动求梯度\n",
    "以求x的二次方为例: $$y = x^2$$\n",
    "1. `attach_grad`: 为梯度计算申请内存\n",
    "2. `record`: 为了减少计算和内存开销，默认条件下MXNet不会记录用于求梯度的计算, 使用record()来记录与梯度有关的计算\n",
    "3. `backward`: 自动求梯度\n",
    "4. 运行模式包括训练模式和预测模式\n",
    "5. `autograd`: 对一般的<b>命令式程序</b>进行求导"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = nd.arange(4).reshape((4, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.attach_grad() # 申请内存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "with autograd.record():  # python 没有为with语句内的变量创建新的作用域\n",
    "    y = 2 * nd.dot(x.T, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[28.]]\n",
       "<NDArray 1x1 @cpu(0)>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y  # 如果 y 不是标量, mxnet会对y所有元素求和, 得到新的变量，再求该变量有关x的梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[1.]\n",
       " [1.]\n",
       " [1.]\n",
       " [1.]]\n",
       "<NDArray 4x1 @cpu(0)>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad == 4 * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "MXNetError",
     "evalue": "[23:46:14] src/imperative/imperative.cc:295: Check failed: !AGInfo::IsNone(*i): Cannot differentiate node because it is not in a computational graph. You need to set is_recording to true or use autograd.record() to save computational graphs for backward. If you want to differentiate the same graph twice, you need to pass retain_graph=True to backward.\nStack trace:\n  [bt] (0) 1   libmxnet.so                         0x00000001139c7929 mxnet::op::NDArrayOpProp::~NDArrayOpProp() + 4473\n  [bt] (1) 2   libmxnet.so                         0x0000000114f4eea1 mxnet::Imperative::Backward(std::__1::vector<mxnet::NDArray*, std::__1::allocator<mxnet::NDArray*> > const&, std::__1::vector<mxnet::NDArray*, std::__1::allocator<mxnet::NDArray*> > const&, std::__1::vector<mxnet::NDArray*, std::__1::allocator<mxnet::NDArray*> > const&, bool, bool, bool) + 16353\n  [bt] (2) 3   libmxnet.so                         0x0000000114e8bffe MXAutogradBackwardEx + 1022\n  [bt] (3) 4   _ctypes.cpython-37m-darwin.so       0x0000000109302367 ffi_call_unix64 + 79\n  [bt] (4) 5   ???                                 0x00007ffee85b7ed0 0x0 + 140732796731088\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMXNetError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-d504727a36bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Cannot differentiate node because it is not in a computational graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Learning/EnvLearning/lib/python3.7/site-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, out_grad, retain_graph, train_mode)\u001b[0m\n\u001b[1;32m   2214\u001b[0m             \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2215\u001b[0m             \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2216\u001b[0;31m             ctypes.c_void_p(0)))\n\u001b[0m\u001b[1;32m   2217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtostype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Learning/EnvLearning/lib/python3.7/site-packages/mxnet/base.py\u001b[0m in \u001b[0;36mcheck_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    251\u001b[0m     \"\"\"\n\u001b[1;32m    252\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMXNetError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMXGetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMXNetError\u001b[0m: [23:46:14] src/imperative/imperative.cc:295: Check failed: !AGInfo::IsNone(*i): Cannot differentiate node because it is not in a computational graph. You need to set is_recording to true or use autograd.record() to save computational graphs for backward. If you want to differentiate the same graph twice, you need to pass retain_graph=True to backward.\nStack trace:\n  [bt] (0) 1   libmxnet.so                         0x00000001139c7929 mxnet::op::NDArrayOpProp::~NDArrayOpProp() + 4473\n  [bt] (1) 2   libmxnet.so                         0x0000000114f4eea1 mxnet::Imperative::Backward(std::__1::vector<mxnet::NDArray*, std::__1::allocator<mxnet::NDArray*> > const&, std::__1::vector<mxnet::NDArray*, std::__1::allocator<mxnet::NDArray*> > const&, std::__1::vector<mxnet::NDArray*, std::__1::allocator<mxnet::NDArray*> > const&, bool, bool, bool) + 16353\n  [bt] (2) 3   libmxnet.so                         0x0000000114e8bffe MXAutogradBackwardEx + 1022\n  [bt] (3) 4   _ctypes.cpython-37m-darwin.so       0x0000000109302367 ffi_call_unix64 + 79\n  [bt] (4) 5   ???                                 0x00007ffee85b7ed0 0x0 + 140732796731088\n\n"
     ]
    }
   ],
   "source": [
    "y.backward()  # Cannot differentiate node because it is not in a computational graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(autograd.is_recording())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(autograd.is_training())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "with autograd.record():\n",
    "    print(autograd.is_recording())\n",
    "    print(autograd.is_training())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对Python控制流求梯度\n",
    "def f(a):\n",
    "    \"\"\"\n",
    "    f(a) = num * a, 梯度为num\n",
    "    \"\"\"\n",
    "    b = a * 2\n",
    "    while b.norm().asscalar() < 1000:\n",
    "        # 使梯度暴增\n",
    "        print(\"b.norm().asscalar(): \", b.norm().asscalar())\n",
    "        b = b * 2\n",
    "    if b.sum().asscalar() > 0:\n",
    "        print(\"b.sum().asscalar() > 0: \", b.sum().asscalar())\n",
    "        c = b\n",
    "    else:\n",
    "        print(\"b.sum().asscalar() <= 0: \", b.sum().asscalar())\n",
    "        c = 100 * b\n",
    "    print(\"c = \", c)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b.norm().asscalar():  1.1425364\n",
      "b.norm().asscalar():  2.2850728\n",
      "b.norm().asscalar():  4.5701456\n",
      "b.norm().asscalar():  9.140291\n",
      "b.norm().asscalar():  18.280582\n",
      "b.norm().asscalar():  36.561165\n",
      "b.norm().asscalar():  73.12233\n",
      "b.norm().asscalar():  146.24466\n",
      "b.norm().asscalar():  292.48932\n",
      "b.norm().asscalar():  584.97864\n",
      "b.sum().asscalar() > 0:  1169.9573\n",
      "c =  \n",
      "[1169.9573]\n",
      "<NDArray 1 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "a = nd.random.normal(shape=1)\n",
    "a.attach_grad()\n",
    "with autograd.record():\n",
    "    c = f(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[2048.]\n",
       "<NDArray 1 @cpu(0)>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[2048.]\n",
       "<NDArray 1 @cpu(0)>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c / a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[0.37723127]\n",
       "<NDArray 1 @cpu(0)>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
