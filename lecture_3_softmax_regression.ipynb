{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax 回归(分类问题)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 快捷键: 对cell 按 m\n",
    "2. 与LR不同在于, 输出层的个数 不是1, 而是类别的个数\n",
    "3. 为什么使用softmax?\n",
    "    - 是因为直接使用输出层有两个问题:\n",
    "        - 输出值的范围不稳定, 难以从直观上判断意义\n",
    "        - 真实标签是散列值, 输出值与离散值很难计算误差\n",
    "    - softmax 将输出值 变换成值为正且和为1的概率分布\n",
    "4. why not 平方损失函数:\n",
    "    - 不需要预测概率 完全 等于 标签概率\n",
    "    - 只需要 最大预测值 对应正确的标签\n",
    "5. why 交叉熵损失函数:\n",
    "    - 更适合衡量两个概率分布\n",
    "    - 关心对正确类别的预测概率，因为只要其值足够大，就可以确保分类结果正确\n",
    "6. 为什么有负号: H = -log (y_hat[i])\n",
    "    - 因为预测概率都小于1, 大于0, 取对数是负数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 贝叶斯公式\n",
    "- 贝叶斯公式: 多大把握能相信一件证据？how much you can trust the evidence\n",
    "- e.g: A代表吃苹果(Apple)事件, B代表吃牛肉(Beef)事件\n",
    "    - P(A|B): 先牛肉后苹果的概率\n",
    "    - P(B|A): 先苹果后牛肉的概率\n",
    "    - ~A: 不吃苹果的事件\n",
    "    - 公式一: $$ P(A|B)= \\frac {P(B|A) P(A)} {P(B)} $$, 解释: 先牛肉后苹果的概率, 等于 吃了苹果也吃了牛肉的事件概率, 除以 吃牛肉事件的概率\n",
    "    - 公式二: $$ P(A|B) P(B) = P(B|A) P(A) $$, 解释: 左边是 吃了牛肉且吃了苹果的概率, 右边是吃了苹果且吃了牛肉的概率, 因为A和B是独立同分布事件, 所以二者相等, 且都表示 吃了牛肉和苹果的事件\n",
    "    - 公式三: $$ P(A|B) = \\frac {P(B|A) P(A)} {P(B|A) P(A) + P(B|~A) P(~A)} $$, 解释: P(B|A) * P(A)表示先苹果后牛肉的概率, P(B|\\~A) * P(\\~A)表示在吃牛肉之前 吃了除苹果以外的东西的概率, 所以, 如果要想在吃牛肉和吃苹果之间有必然的联系, 那么就需要除了苹果, 什么都不用吃, 也就是 P(\\~A) 为 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 极大似然估计\n",
    "- definition: 利用已知的样本数据信息, 反推 最大概率导致 样本结果的参数值\n",
    "- 给定观察数据, 评估模型参数\n",
    "- 概率统计, 概率 is not equal to 统计:\n",
    "    - 概率: \n",
    "        - given: 模型, 参数\n",
    "        - result: 模型结果的特性\n",
    "    - 统计:\n",
    "        - given: 数据\n",
    "        - result: predicted 模型和参数\n",
    "    - in summary: 概率是已知模型和参数，推数据。统计是已知数据，推模型和参数\n",
    "- 似然函数 vs 概率函数:\n",
    "    - 对于, x 是 数据, θ 是 模型参数 $$ p(x|\\theta) $$\n",
    "    - x已知, θ是变量: 似然函数\n",
    "    - θ已知, x是变量: 概率函数\n",
    "- reference:\n",
    "    - https://blog.csdn.net/u011508640/article/details/72815981\n",
    "    - https://zhuanlan.zhihu.com/p/26614750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import gluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预处理数据\n",
    "def load_data_fashion_mnist(batch_size, resize=None):\n",
    "    \"\"\"Download the Fashion-MNIST dataset and then load into memory.\"\"\"\n",
    "    dataset = gluon.data.vision\n",
    "    trans = [dataset.transforms.Resize(resize)] if resize else []\n",
    "    trans.append(dataset.transforms.ToTensor())\n",
    "    trans = dataset.transforms.Compose(trans)\n",
    "    mnist_train = dataset.FashionMNIST(train=True).transform_first(trans)\n",
    "    mnist_test = dataset.FashionMNIST(train=False).transform_first(trans)\n",
    "    return (gluon.data.DataLoader(mnist_train, batch_size, shuffle=True,\n",
    "                                  num_workers=get_dataloader_workers()),\n",
    "            gluon.data.DataLoader(mnist_test, batch_size, shuffle=False,\n",
    "                                  num_workers=get_dataloader_workers()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
