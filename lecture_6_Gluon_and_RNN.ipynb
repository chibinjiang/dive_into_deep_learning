{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用 Gluon 实现RNN, 创作歌词\n",
    "### 1. 需要 想想怎么在 Colab 解决 代码复用的问题\n",
    "- 把 包的引入在方法内\n",
    "\n",
    "### 2. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备 Google Colab 环境: 在Runtime中选择 GPU\n",
    "# 拉取数据集\n",
    "pwd = !pwd\n",
    "if 'dive_into_deep_learning' not in pwd[0]:\n",
    "    ! git clone https://github.com/chibinjiang/dive_into_deep_learning.git\n",
    "    # 进入到和开发环境相似的工作目录\n",
    "%cd /content/dive_into_deep_learning/\n",
    "# 安装依赖\n",
    "! pip install mxnet-cu101mkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import time\n",
    "import zipfile\n",
    "import traceback\n",
    "import mxnet as mx\n",
    "from mxnet import autograd, gluon, init, nd\n",
    "from mxnet.gluon import loss as gloss, nn, rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据集\n",
    "with zipfile.ZipFile('DataResources/Chapter_6/jaychou_lyrics.txt.zip') as zin:\n",
    "    with zin.open('jaychou_lyrics.txt') as f:\n",
    "        corpus_chars = f.read().decode('utf-8')\n",
    "corpus_chars = re.sub(r'\\s+', ' ', corpus_chars)\n",
    "idx_to_char = list(set(corpus_chars))\n",
    "char_to_idx = dict([(char, i) for i, char in enumerate(idx_to_char)])\n",
    "vocab_size = len(char_to_idx)\n",
    "corpus_indices = [char_to_idx[char] for char in corpus_chars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义 RNN 模型\n",
    "def gen_net(num_hiddens, batch_size):\n",
    "    _rnn = rnn.RNN(num_hiddens)\n",
    "    _rnn.initialize()\n",
    "    _rnn.begin_state(batch_size=batch_size)\n",
    "    return _rnn\n",
    "    \n",
    "class RNN(nn.Block):\n",
    "    def __init__(self, num_hiddens, batch_size, vocab_size, **kwargs):\n",
    "        super(RNN, self).__init__(**kwargs)\n",
    "        self.rnn = gen_net(num_hiddens, batch_size)\n",
    "        self.vocab_size = vocab_size\n",
    "        self.dense = nn.Dense(vocab_size)  # 为什么需要一个全连接层\n",
    "    \n",
    "    def forward(self, inputs, state):\n",
    "        # 将输入转置成(num_steps, batch_size)后获取one-hot向量表示\n",
    "        X = nd.one_hot(inputs.T, self.vocab_size)\n",
    "        Y, state = self.rnn(X, state)\n",
    "        # 全连接层会首先将Y的形状变成(num_steps * batch_size, num_hiddens)，它的输出\n",
    "        # 形状为(num_steps * batch_size, vocab_size)\n",
    "        output = self.dense(Y.reshape((-1, Y.shape[-1])))\n",
    "        return output, state\n",
    "    \n",
    "    def begin_state(self, *args, **kwargs):\n",
    "        return self.rnn.begin_state(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_net = gen_net(100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30, 2, 100), [\n",
       "  [[[1.5278673  0.         1.0445228  0.         0.         1.6484566\n",
       "     1.8354766  0.         0.         0.         1.1338558  0.\n",
       "     0.42351055 0.         0.         0.         0.         1.3539939\n",
       "     0.31653637 0.         0.         0.4922253  0.         1.4564292\n",
       "     1.1331655  0.08769092 0.2364367  0.         0.5829359  3.5316272\n",
       "     0.         0.         0.08696572 0.         1.5529106  0.6949022\n",
       "     0.         0.57017994 0.         0.         0.19693512 0.\n",
       "     0.         0.         0.08501232 1.3938953  0.         0.5927223\n",
       "     0.         0.         0.         1.7381938  0.7154095  0.3993885\n",
       "     0.         0.         0.5789365  0.16283596 0.         0.\n",
       "     4.122617   0.         0.         0.7438283  0.         0.9080451\n",
       "     1.1469073  0.66469157 0.00958797 0.         0.7123618  0.\n",
       "     0.67446774 0.         0.08351076 2.5886292  0.         1.9853334\n",
       "     1.7640082  0.         0.15815529 0.22243357 0.         0.\n",
       "     0.7966601  0.         1.4879034  0.         0.43341446 0.\n",
       "     0.85194176 1.5169411  0.         0.4188936  0.         1.4793936\n",
       "     0.11655658 0.         0.         0.        ]\n",
       "    [0.49272102 0.         1.3639603  0.         0.13596529 0.85960716\n",
       "     1.7749538  0.         0.         0.         0.         0.\n",
       "     1.1927054  1.3133019  0.         0.         0.8974129  1.3199869\n",
       "     0.3085855  0.         0.         0.03820897 1.1344846  0.38984716\n",
       "     0.94526803 0.7019026  0.         0.         0.44088465 2.4963117\n",
       "     0.         0.         0.         0.         0.86436504 0.40091437\n",
       "     0.52114135 1.4102024  0.         0.         0.         0.\n",
       "     0.         0.         0.1185559  1.2798615  0.         0.15354332\n",
       "     0.         0.         0.         0.9478243  1.6855005  0.8527158\n",
       "     0.3331138  0.         0.5354203  0.20027965 0.         0.\n",
       "     1.9365169  0.         1.1820314  1.1050293  0.         0.5274993\n",
       "     0.         1.3106338  0.15993264 0.         0.82656825 0.\n",
       "     0.6445401  0.         0.         1.923662   0.         1.6844945\n",
       "     0.20763232 0.         0.04808267 0.38708332 0.1509037  0.\n",
       "     0.6003119  0.         2.3726835  0.         0.44051892 0.\n",
       "     0.         1.9628005  0.13584477 0.         0.         1.9289321\n",
       "     0.         0.         0.         0.        ]]]\n",
       "  <NDArray 1x2x100 @cpu(0)>])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_state = temp_net.begin_state(batch_size=2)\n",
    "X = nd.random.uniform(shape=(30, 2, vocab_size))\n",
    "Y, state_new = temp_net(X, init_state)\n",
    "(Y.shape, state_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rnn_gluon(prefix, num_chars, model, vocab_size, ctx, idx_to_char, char_to_idx):\n",
    "    \"\"\"\n",
    "    预测prefix 之后的歌词\n",
    "    \"\"\"\n",
    "    state = model.begin_state(batch_size=1, ctx=ctx)  # 使用model的成员函数来初始化隐藏状态\n",
    "    output = [char_to_idx[prefix[0]]]\n",
    "    for t in range(num_chars + len(prefix) - 1):\n",
    "        X = nd.array([output[-1]], ctx=ctx).reshape((1, 1))\n",
    "        (Y, state) = model(X, state)  # 前向计算不需要传入模型参数\n",
    "        if t < len(prefix) - 1:\n",
    "            output.append(char_to_idx[prefix[t + 1]])\n",
    "        else:\n",
    "            output.append(int(Y.argmax(axis=1).asscalar()))\n",
    "    return ''.join([idx_to_char[i] for i in output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_gpu(gpu_number=0):\n",
    "    \"\"\"\n",
    "        Return gpu(i) if exists, otherwise return cpu().\n",
    "    \"\"\"\n",
    "#     import traceback\n",
    "    try:\n",
    "        _ = mx.nd.array([1, 2, 3], ctx=mx.gpu(gpu_number))\n",
    "        print(\"Try GPU: {}\".format(gpu_number))\n",
    "    except mx.MXNetError:\n",
    "#         traceback.print_exc()\n",
    "        print(\"Try CPU: {}\".format(gpu_number))\n",
    "        return mx.cpu()\n",
    "    return mx.gpu(gpu_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Try CPU: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'分开贪期隧砍術演墨币样阵'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctx = try_gpu()\n",
    "model = RNN(256, 2, vocab_size)\n",
    "model.initialize(force_reinit=True, ctx=ctx)\n",
    "predict_rnn_gluon('分开', 10, model, vocab_size, ctx, idx_to_char, char_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_iter_consecutive(corpus_indices, batch_size, num_steps, ctx=None):\n",
    "    \"\"\"\n",
    "    相邻采样: 相邻 epoch 的 batch_size 样本是相邻的\n",
    "    Sample mini-batches in a consecutive order from sequential data.\n",
    "    \"\"\"\n",
    "    corpus_indices = nd.array(corpus_indices, ctx=ctx)\n",
    "    data_len = len(corpus_indices)\n",
    "    batch_len = data_len // batch_size\n",
    "    indices = corpus_indices[0 : batch_size * batch_len].reshape((\n",
    "        batch_size, batch_len))  # 只要 前面的batch_size * batch_len 个 \n",
    "    epoch_size = (batch_len - 1) // num_steps\n",
    "    for i in range(epoch_size):\n",
    "        i = i * num_steps\n",
    "        X = indices[:, i : i + num_steps]\n",
    "        Y = indices[:, i + 1 : i + num_steps + 1]\n",
    "        yield X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 剪裁梯度\n",
    "def grad_clipping(params, theta, ctx):\n",
    "    norm = nd.array([0], ctx)\n",
    "    for param in params:\n",
    "        norm += (param.grad ** 2).sum()\n",
    "    norm = norm.sqrt().asscalar()\n",
    "    if norm > theta:\n",
    "        for param in params:\n",
    "            param.grad[:] *= theta / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict_rnn_gluon(model, num_hiddens, vocab_size, ctx,\n",
    "                                corpus_indices, idx_to_char, char_to_idx,\n",
    "                                num_epochs, num_steps, lr, clipping_theta,\n",
    "                                batch_size, pred_period, pred_len, prefixes):\n",
    "    perplexity_hist = list()\n",
    "    loss = gloss.SoftmaxCrossEntropyLoss()\n",
    "    model.initialize(ctx=ctx, force_reinit=True, init=init.Normal(0.01))\n",
    "    trainer = gluon.Trainer(model.collect_params(), 'sgd',\n",
    "                            {'learning_rate': lr, 'momentum': 0, 'wd': 0})\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        l_sum, n, start = 0.0, 0, time.time()\n",
    "        data_iter = data_iter_consecutive(\n",
    "            corpus_indices, batch_size, num_steps, ctx)\n",
    "        state = model.begin_state(batch_size=batch_size, ctx=ctx)\n",
    "        for X, Y in data_iter:\n",
    "            for s in state:\n",
    "                s.detach()\n",
    "            with autograd.record():\n",
    "                (output, state) = model(X, state)\n",
    "                y = Y.T.reshape((-1,))\n",
    "                l = loss(output, y).mean()\n",
    "            l.backward()\n",
    "            # 梯度裁剪\n",
    "            params = [p.data() for p in model.collect_params().values()]\n",
    "            grad_clipping(params, clipping_theta, ctx)\n",
    "            trainer.step(1)  # 因为已经误差取过均值，梯度不用再做平均\n",
    "            l_sum += l.asscalar() * y.size\n",
    "            n += y.size\n",
    "        perplexity = math.exp(l_sum / n)\n",
    "        perplexity_hist.append(perplexity)\n",
    "        if (epoch + 1) % pred_period == 0:\n",
    "            print('epoch %d, perplexity %f, time %.2f sec' % (epoch + 1, perplexity, time.time() - start))\n",
    "            for prefix in prefixes:\n",
    "                print(' -', predict_rnn_gluon(prefix, pred_len, model, vocab_size, ctx, idx_to_char, char_to_idx))\n",
    "    return perplexity_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hiddens, num_steps = 256, 35\n",
    "num_epochs, batch_size, lr, clipping_theta = 300, 32, 100, 0.01\n",
    "pred_period, pred_len, prefixes = 10, 50, ['分开', '不分开', '我静静地']\n",
    "perplexities = train_and_predict_rnn_gluon(model, num_hiddens, vocab_size, ctx,\n",
    "                            corpus_indices, idx_to_char, char_to_idx,\n",
    "                            num_epochs, num_steps, lr, clipping_theta,\n",
    "                            batch_size, pred_period, pred_len, prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexities"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
