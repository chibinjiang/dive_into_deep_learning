{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QfplSxJ-Kgmz"
   },
   "source": [
    "## 使用 Gluon 实现RNN, 创作歌词\n",
    "### 1. 为什么简介实现比从零实现快这么多\n",
    "- \"简介实现\"每次迭代 都会从计算图分离隐含状态, 导致模型梯度参数只依赖当前的批量序列, 从而减小 每次迭代的计算开销\n",
    "\n",
    "### 2. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 132183,
     "status": "ok",
     "timestamp": 1582513771862,
     "user": {
      "displayName": "Zhibin Jiang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBtCQsggsYbhwo7wHg54VYCeP9aYN5gmmACw6tP=s64",
      "userId": "14703827957503696342"
     },
     "user_tz": -480
    },
    "id": "ue9DHpcXKgm1",
    "outputId": "81a5525e-5a61-4e30-a9ce-638bdc945d46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mxnet-cu101mkl\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/77/aa/3bab75904a39935cc71b68bec100f51c9ff061d0244bcd68037a6d57aba4/mxnet_cu101mkl-1.5.1.post0-py2.py3-none-manylinux1_x86_64.whl (587.7MB)\n",
      "\u001b[K     |████████████████████████████████| 587.7MB 28kB/s \n",
      "\u001b[?25hCollecting graphviz<0.9.0,>=0.8.1\n",
      "  Downloading https://files.pythonhosted.org/packages/53/39/4ab213673844e0c004bed8a0781a0721a3f6bb23eb8854ee75c236428892/graphviz-0.8.4-py2.py3-none-any.whl\n",
      "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu101mkl) (2.21.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu101mkl) (1.17.5)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu101mkl) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu101mkl) (2019.11.28)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu101mkl) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu101mkl) (1.24.3)\n",
      "Installing collected packages: graphviz, mxnet-cu101mkl\n",
      "  Found existing installation: graphviz 0.10.1\n",
      "    Uninstalling graphviz-0.10.1:\n",
      "      Successfully uninstalled graphviz-0.10.1\n",
      "Successfully installed graphviz-0.8.4 mxnet-cu101mkl-1.5.1.post0\n",
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n",
      "/content/drive/My Drive/Colab Notebooks/dive_into_deep_learning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/content/drive/My Drive/Colab Notebooks/dive_into_deep_learning'"
      ]
     },
     "execution_count": 1,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "! pip install mxnet-cu101mkl\n",
    "from google.colab import drive\n",
    "gd_path = '/content/drive'\n",
    "drive.mount(gd_path)\n",
    "%cd '/content/drive/My Drive/Colab Notebooks/dive_into_deep_learning'\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "34WTDN8iKgm5"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import time\n",
    "import zipfile\n",
    "import traceback\n",
    "import mxnet as mx\n",
    "from mxnet import autograd, gluon, init, nd\n",
    "from mxnet.gluon import loss as gloss, nn, rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sEC6qRMZKgm8"
   },
   "outputs": [],
   "source": [
    "# 加载数据集\n",
    "with zipfile.ZipFile('DataResources/Chapter_6/jaychou_lyrics.txt.zip') as zin:\n",
    "    with zin.open('jaychou_lyrics.txt') as f:\n",
    "        corpus_chars = f.read().decode('utf-8')\n",
    "corpus_chars = re.sub(r'\\s+', ' ', corpus_chars)\n",
    "idx_to_char = list(set(corpus_chars))\n",
    "char_to_idx = dict([(char, i) for i, char in enumerate(idx_to_char)])\n",
    "vocab_size = len(char_to_idx)\n",
    "corpus_indices = [char_to_idx[char] for char in corpus_chars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jnn3hf8kKgm-"
   },
   "outputs": [],
   "source": [
    "# 定义 RNN 模型\n",
    "def gen_net(num_hiddens, batch_size):\n",
    "    _rnn = rnn.RNN(num_hiddens)\n",
    "    _rnn.initialize()\n",
    "    _rnn.begin_state(batch_size=batch_size)\n",
    "    return _rnn\n",
    "    \n",
    "class RNN(nn.Block):\n",
    "    def __init__(self, num_hiddens, batch_size, vocab_size, **kwargs):\n",
    "        super(RNN, self).__init__(**kwargs)\n",
    "        self.rnn = gen_net(num_hiddens, batch_size)\n",
    "        self.vocab_size = vocab_size\n",
    "        self.dense = nn.Dense(vocab_size)  # 为什么需要一个全连接层\n",
    "    \n",
    "    def forward(self, inputs, state):\n",
    "        # 将输入转置成(num_steps, batch_size)后获取one-hot向量表示\n",
    "        X = nd.one_hot(inputs.T, self.vocab_size)\n",
    "        Y, state = self.rnn(X, state)\n",
    "        # 全连接层会首先将Y的形状变成(num_steps * batch_size, num_hiddens)，它的输出\n",
    "        # 形状为(num_steps * batch_size, vocab_size)\n",
    "        output = self.dense(Y.reshape((-1, Y.shape[-1])))\n",
    "        return output, state\n",
    "    \n",
    "    def begin_state(self, *args, **kwargs):\n",
    "        return self.rnn.begin_state(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z-q8XxfuKgnB"
   },
   "outputs": [],
   "source": [
    "temp_net = gen_net(100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 629
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 507,
     "status": "ok",
     "timestamp": 1582513932702,
     "user": {
      "displayName": "Zhibin Jiang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBtCQsggsYbhwo7wHg54VYCeP9aYN5gmmACw6tP=s64",
      "userId": "14703827957503696342"
     },
     "user_tz": -480
    },
    "id": "TSuE7UjrKgnE",
    "outputId": "b29948d7-8b5f-4972-9c63-010b96db2241"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30, 2, 100), [\n",
       "  [[[0.         0.         1.0604693  0.7939049  0.         0.\n",
       "     0.40115237 0.         0.         0.         1.653013   0.\n",
       "     0.         2.4500334  0.         1.7684158  0.5570866  0.\n",
       "     0.         0.         0.         1.8967252  1.520531   0.16472216\n",
       "     0.31395215 0.         0.         0.44583786 0.         0.\n",
       "     2.8692446  0.         0.         0.         1.166519   0.\n",
       "     0.         0.         0.         0.         0.         0.7190442\n",
       "     0.         3.140932   0.         0.61330855 0.         0.63296187\n",
       "     0.5235083  0.56653047 1.4101675  0.8184509  0.19092263 0.\n",
       "     0.98904157 0.         0.         0.2568788  0.09498417 0.\n",
       "     0.         1.6761665  0.         1.2460227  0.         1.1604192\n",
       "     0.         1.5758954  0.         0.         0.41418585 1.0927155\n",
       "     0.84002507 1.0490992  1.5553081  0.         0.75275314 0.\n",
       "     2.5894449  0.597352   0.37891552 1.0617347  1.4261123  0.8206196\n",
       "     0.10223021 0.65250546 0.         0.         0.63045084 0.32392147\n",
       "     0.8184449  0.         0.         0.         0.1256648  1.1608706\n",
       "     0.         1.4146222  0.         0.64681673]\n",
       "    [0.         0.         0.         0.7704772  0.         0.\n",
       "     0.24473825 0.         0.         0.         0.         0.\n",
       "     0.         2.7262003  0.         2.7129626  0.         0.\n",
       "     0.         0.         0.         0.68110955 2.1788507  0.\n",
       "     1.0736357  0.         0.         0.         0.         0.\n",
       "     1.9406835  0.         0.         0.         2.2136288  0.21491024\n",
       "     0.         0.57344383 0.55405766 0.03035553 0.         0.17232567\n",
       "     0.         2.2054965  0.         0.         0.         0.06541376\n",
       "     0.7185329  0.         0.96715343 0.05874265 2.4711187  0.2365528\n",
       "     0.         0.11144584 0.         0.         1.0295649  0.\n",
       "     0.         2.9488375  0.         0.9668293  0.         0.94967896\n",
       "     0.         0.         0.         0.         0.17713471 0.74704885\n",
       "     0.090068   0.3327678  1.6084299  0.         1.9474947  0.\n",
       "     3.0149217  0.         1.3186547  0.48121744 2.2474184  0.58629966\n",
       "     0.         0.         0.         0.         0.04099166 0.\n",
       "     0.         0.         0.         0.         0.         1.0014306\n",
       "     0.         0.66176075 0.         1.6048617 ]]]\n",
       "  <NDArray 1x2x100 @cpu(0)>])"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_state = temp_net.begin_state(batch_size=2)\n",
    "X = nd.random.uniform(shape=(30, 2, vocab_size))\n",
    "Y, state_new = temp_net(X, init_state)\n",
    "(Y.shape, state_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ue2eSFlSKgnI"
   },
   "outputs": [],
   "source": [
    "def predict_rnn_gluon(prefix, num_chars, model, vocab_size, ctx, idx_to_char, char_to_idx):\n",
    "    \"\"\"\n",
    "    预测prefix 之后的歌词\n",
    "    \"\"\"\n",
    "    state = model.begin_state(batch_size=1, ctx=ctx)  # 使用model的成员函数来初始化隐藏状态\n",
    "    output = [char_to_idx[prefix[0]]]\n",
    "    for t in range(num_chars + len(prefix) - 1):\n",
    "        X = nd.array([output[-1]], ctx=ctx).reshape((1, 1))\n",
    "        (Y, state) = model(X, state)  # 前向计算不需要传入模型参数\n",
    "        if t < len(prefix) - 1:\n",
    "            output.append(char_to_idx[prefix[t + 1]])\n",
    "        else:\n",
    "            output.append(int(Y.argmax(axis=1).asscalar()))\n",
    "    return ''.join([idx_to_char[i] for i in output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vwbpKX5xKgnL"
   },
   "outputs": [],
   "source": [
    "def try_gpu(gpu_number=0):\n",
    "    \"\"\"\n",
    "        Return gpu(i) if exists, otherwise return cpu().\n",
    "    \"\"\"\n",
    "    try:\n",
    "        _ = mx.nd.array([1, 2, 3], ctx=mx.gpu(gpu_number))\n",
    "        print(\"Try GPU: {}\".format(gpu_number))\n",
    "    except mx.MXNetError:\n",
    "        print(\"Try CPU: {}\".format(gpu_number))\n",
    "        return mx.cpu()\n",
    "    return mx.gpu(gpu_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7600,
     "status": "ok",
     "timestamp": 1582513943016,
     "user": {
      "displayName": "Zhibin Jiang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBtCQsggsYbhwo7wHg54VYCeP9aYN5gmmACw6tP=s64",
      "userId": "14703827957503696342"
     },
     "user_tz": -480
    },
    "id": "Ev8xo6ioKgnN",
    "outputId": "94b9c218-98c7-4c93-aabe-683806885417"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Try GPU: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'分开寇褆孔严统昏铩印抢声'"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctx = try_gpu()\n",
    "model = RNN(256, 2, vocab_size)\n",
    "model.initialize(force_reinit=True, ctx=ctx)\n",
    "predict_rnn_gluon('分开', 10, model, vocab_size, ctx, idx_to_char, char_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1k8XW3KAKgnR"
   },
   "outputs": [],
   "source": [
    "def data_iter_consecutive(corpus_indices, batch_size, num_steps, ctx=None):\n",
    "    \"\"\"\n",
    "    相邻采样: 相邻 epoch 的 batch_size 样本是相邻的\n",
    "    Sample mini-batches in a consecutive order from sequential data.\n",
    "    \"\"\"\n",
    "    corpus_indices = nd.array(corpus_indices, ctx=ctx)\n",
    "    data_len = len(corpus_indices)\n",
    "    batch_len = data_len // batch_size\n",
    "    indices = corpus_indices[0 : batch_size * batch_len].reshape((\n",
    "        batch_size, batch_len))  # 只要 前面的batch_size * batch_len 个 \n",
    "    epoch_size = (batch_len - 1) // num_steps\n",
    "    for i in range(epoch_size):\n",
    "        i = i * num_steps\n",
    "        X = indices[:, i : i + num_steps]\n",
    "        Y = indices[:, i + 1 : i + num_steps + 1]\n",
    "        yield X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o4x6qDzpKgnT"
   },
   "outputs": [],
   "source": [
    "# 剪裁梯度\n",
    "def grad_clipping(params, theta, ctx):\n",
    "    norm = nd.array([0], ctx)\n",
    "    for param in params:\n",
    "        norm += (param.grad ** 2).sum()\n",
    "    norm = norm.sqrt().asscalar()\n",
    "    if norm > theta:\n",
    "        for param in params:\n",
    "            param.grad[:] *= theta / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vu7wQ7YEKgnW"
   },
   "outputs": [],
   "source": [
    "def train_and_predict_rnn_gluon(model, num_hiddens, vocab_size, ctx,\n",
    "                                corpus_indices, idx_to_char, char_to_idx,\n",
    "                                num_epochs, num_steps, lr, clipping_theta,\n",
    "                                batch_size, pred_period, pred_len, prefixes):\n",
    "    perplexity_hist = list()\n",
    "    loss = gloss.SoftmaxCrossEntropyLoss()\n",
    "    model.initialize(ctx=ctx, force_reinit=True, init=init.Normal(0.01))\n",
    "    trainer = gluon.Trainer(model.collect_params(), 'sgd',\n",
    "                            {'learning_rate': lr, 'momentum': 0, 'wd': 0})\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        l_sum, n, start = 0.0, 0, time.time()\n",
    "        data_iter = data_iter_consecutive(\n",
    "            corpus_indices, batch_size, num_steps, ctx)\n",
    "        state = model.begin_state(batch_size=batch_size, ctx=ctx)\n",
    "        for X, Y in data_iter:\n",
    "            for s in state:\n",
    "                s.detach()\n",
    "            with autograd.record():\n",
    "                (output, state) = model(X, state)\n",
    "                y = Y.T.reshape((-1,))\n",
    "                l = loss(output, y).mean()\n",
    "            l.backward()\n",
    "            # 梯度裁剪\n",
    "            params = [p.data() for p in model.collect_params().values()]\n",
    "            grad_clipping(params, clipping_theta, ctx)\n",
    "            trainer.step(1)  # 因为已经误差取过均值，梯度不用再做平均\n",
    "            l_sum += l.asscalar() * y.size\n",
    "            n += y.size\n",
    "        perplexity = math.exp(l_sum / n)\n",
    "        perplexity_hist.append(perplexity)\n",
    "        if (epoch + 1) % pred_period == 0:\n",
    "            print('epoch %d, perplexity %f, time %.2f sec' % (epoch + 1, perplexity, time.time() - start))\n",
    "            for prefix in prefixes:\n",
    "                print(' -', predict_rnn_gluon(prefix, pred_len, model, vocab_size, ctx, idx_to_char, char_to_idx))\n",
    "    return perplexity_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 160167,
     "status": "ok",
     "timestamp": 1582514289995,
     "user": {
      "displayName": "Zhibin Jiang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBtCQsggsYbhwo7wHg54VYCeP9aYN5gmmACw6tP=s64",
      "userId": "14703827957503696342"
     },
     "user_tz": -480
    },
    "id": "BX3yesBBKgnY",
    "outputId": "80940a38-e25c-4ace-958a-6d9c7b438f27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, perplexity 296.871192, time 0.51 sec\n",
      " - 分开 我们 我的 我 我的 我 我的 我 我的 我 我的 我 我的 我 我的 我 我的 我 我的 我 我\n",
      " - 不分开 我们的 我 我的 我 我的 我 我的 我 我的 我 我的 我 我的 我 我的 我 我的 我 我的 \n",
      " - 我静静地 我的爱 我的爱 我的爱 我的爱 我的爱 我的爱 我的爱 我的爱 我的爱 我的爱 我的爱 我的爱 我\n",
      "epoch 20, perplexity 170.466381, time 0.53 sec\n",
      " - 分开 不用麻烦 我们不是 你的灵界 在我的爱泪 在我的手气 我们了着 一个一直 我们了感 你的世界 在我\n",
      " - 不分开 我们不能 你的世界 你的爱界 你的爱界 你的爱界 你的爱界 你的爱界 你的爱界 你的爱界 你的爱界\n",
      " - 我静静地 你的眼界 你的爱界 你的爱界 你的爱界 你的爱界 你的爱界 你的爱界 你的爱界 你的爱界 你的爱界\n",
      "epoch 30, perplexity 97.244393, time 0.50 sec\n",
      " - 分开 我们 如些我 娘中 人 Ya 一切 me 我用 我们 我不光 不是我 爱着不人 你的灵魂 你我等的\n",
      " - 不分开 不是我 的手魂人 一个界 的灵魂只剩下一种 等空的客倾 我们上的世界 在空地 那子 我在 我很 我\n",
      " - 我静静地 你的眼溃 你我等不到 你的眼界 你的等里 你我的感情 我在等待 你就会 你手 我们 我不光 不是我\n",
      "epoch 40, perplexity 59.051912, time 0.50 sec\n",
      " - 分开 我们 如单我 想手 那里 豆腐 豆e 赶e 功紧 功紧 功e 功紧 功紧 功紧 功紧 功紧 功紧 \n",
      " - 不分开 不是我们在泪 会有我们的泪诺 能说你说 我有你 对手 你说 我有你 爱情 我 再感了 一直一步 等\n",
      " - 我静静地 你说不该 让我们乘着阳光 看着远方河个天 说我的善 在你比外的溪界 你说你方越 天涯的手笑 我在等\n",
      "epoch 50, perplexity 39.258070, time 0.50 sec\n",
      " - 分开 我们在感力 我在赶一间 你的年如 我不想 你了那果 你始了 不来成 你在空 对远了 你在空 对远的\n",
      " - 不分开 不是我们的天 下一点 原a 不用麻烦了 不用麻 我当不是不来 你的眼溃 你会的感 我不需 你的爱果\n",
      " - 我静静地 你在那窗 在小村外的溪边 我说你地越 天涯银下 你的声容 我 在我 你的表念 你的你的 泪过的人 \n",
      "epoch 60, perplexity 28.386920, time 0.53 sec\n",
      " - 分开 你的爱溢在问装零碎 反色的让 人手着 不能太 你手用 你说笑 不需了 不让麻 不是不忆永 发间的思\n",
      " - 不分开 我就想走开 我不要再 帮你了 你累了 你说了 你说了 你说了 你说了 你说了 你说了 你说了 你说\n",
      " - 我静静地 你是如雪前必 我用光打开了天 化身为龙 那山地 的日出只剩下一种 等待英雄 我就是那条龙 我右拳打\n",
      "epoch 70, perplexity 21.892907, time 0.50 sec\n",
      " - 分开 你的爱前属勉象 却奈看到我去出的鲜花 我伤的机位蔓的好不的那著我很夫的脸以 让我们盘半兽光 看景冲\n",
      " - 不分开烦了 不用麻烦了太不能一点把气 我看不出松严人怎么很 几空上不是我要的天堂景象 沉沦假象 你只会感到\n",
      " - 我静静地你的感觉 原格就容的手征 我说店小静 三两银织不够 景右入睛上漫当的有窗海 我记的风情 在空中秋远 \n",
      "epoch 80, perplexity 17.849276, time 0.50 sec\n",
      " - 分开 你有一场 在小丽 的小出调整了一种 等待英雄 我当她有力 加甚么月 或许都迫 我的感界 你已美不同\n",
      " - 不分开 其等的感觉 不用 情哈我的相球变暗 别过了别人 我等待有些瘦 未涯的很精准你更像一句 从一点杨柳 \n",
      " - 我静静地 你在那地前 过天的画笑 全都是我不对 细数惭愧的人装那我 想不休 语气风埃台 你在空有了 当冷人 \n",
      "epoch 90, perplexity 15.230994, time 0.49 sec\n",
      " - 分开 你的爱影 微微上的 娘接 如间的人像 我将头悔重 我攻势 永色的 不间就 爱手情有些 不要吵 摇滚\n",
      " - 不分开 其上的手觉 让我的手脸 最你变 失让回忆 我用格能 再得了 你却了 你仍终野 我最你几回 我攻势如\n",
      " - 我静静地 别多你的爱邪 损止你说再难 这没有时南 我在身空 凄永她的酒窗 我把店安静 三两银够面够 景别入睛\n",
      "epoch 100, perplexity 13.235669, time 0.49 sec\n",
      " - 分开 你的橱影这窗外 原 我把你的伤写 描述你说送见 这一台梦在我手的有点你就想 你听手为前来续不及 不\n",
      " - 不分开 海鸟的感觉 后我的眼脸倒最一场 旧湖 我在一场学移里加花 好开的影在干枯着回了很义 我不能够该回对\n",
      " - 我静静地变 我就要加你读笑 有你最善的世开 不来污染的转生 你说还好累 侧脸银的爱刚 计法没有回见 你妆的爱\n",
      "epoch 110, perplexity 12.096060, time 0.50 sec\n",
      " - 分开 你的爱影 失微 娘 无不到我 分手的珊瑚 全在等待在想 我向天去 你就会有男 有目么的古快 她亮 \n",
      " - 不分开 海上的方水 我在人待重来 天空仍灿 你们的爱情 梦空的资群 升刺的眼泪 焦化的答像 失化的手像 不\n",
      " - 我静静地 别多情的感光 我也欢的二子有城落事 嘿 这么说 谁成了 你看了 你说了 你手了 你手了 你手了 你\n",
      "epoch 120, perplexity 10.737808, time 0.51 sec\n",
      " - 分开始 你的微笑 失去 心眼无义 永无 竟飘积之伤害 只了没家里的风光 在我脸忘场旧清气可陪 最信的桥梁\n",
      " - 不分开 海就让你的脸释 我说速的扭物 城止难我 娘魔清人 你的生音 用一直带 就了一路蓝外的资格摊 缓睛心\n",
      " - 我静静地了 我用远不用 开该我的爱前 我 你的指尖在西元前一深 被外不存吵的梦女 让我终绷喘 你说不起 我睁\n",
      "epoch 130, perplexity 9.915124, time 0.50 sec\n",
      " - 分开 你的身影 失去上的 你一定的 你永了 你一笑的爱 有我全不跟 梦在走梦里弹奏料 竟记我的爱托 我 \n",
      " - 不分开 海在我在前里多 我会本精 别人的手式 何答了风着 我知道在些旁 对着你 觉爱解 你说我有等空 别我\n",
      " - 我静静地 让我女略着阳光 海上冲浪 别引她人 木一直 等硬 娘子 我战中的第 有一窗外平 我开 如双我 o头\n",
      "epoch 140, perplexity 9.334445, time 0.50 sec\n",
      " - 分开始 你的身笑幽失 我彻底开到了谁 邀明月龙 那山地重脏 又 那天 你的微切幽默 你默 我像你的脸衣 \n",
      " - 不分开 走就让你的脸牌 微刚你好累个你 印向到著去 我们身害 回来 手 哈得着龙 你没有回忆 没有你手的感\n",
      " - 我静静地了e 我十没有很子 你们远 你在那难 画自了 这时候 啦变真人 等待止 你却不着 来哈掉 我 你的指\n",
      "epoch 150, perplexity 8.550189, time 0.51 sec\n",
      " - 分开始不能 说了时间 我面序努力向你奔跑 我吃送表情了一个称 琥录眼前不重阻来 但做了这种外单 我用悄你\n",
      " - 不分开 海在我在前的叠方 你好关不同再出了 因在最琵吹弹奏逅 冷咖没有 给我在空你前月 我用是陪傻了谁 化\n",
      " - 我静静地你 陪我会吃汉邦 说我的手lu后s熟的飞人 你的爱真这直近徊却 牛不能谁这回忍 回到你的手邪幽默 从\n",
      "epoch 160, perplexity 8.172170, time 0.50 sec\n",
      " - 分开始 在多丽中弹 还是你的我 有双莫没有祝 我送你走追最后缺能就是我 没开你受做的大 你跟我会了个人 \n",
      " - 不分开 连就让走的圆装 在原地上了等面 还能该此 当鬼咿 我一个武北 你不能再不回 爱情钨灿 海手了双截棍\n",
      " - 我静静地 这些挽扯 当呀的浅\\笑 狼迎过嚎 蝠开用双 睁一直刮 我像枝桠 帮香为龙 这个放 对诉后 我把狠 \n",
      "epoch 170, perplexity 7.596425, time 0.50 sec\n",
      " - 分开始 在多丽外不是始能 能不能 睁走一埃就说不要 不懂在非话渐蜻蜓 小十当 娘异的手式燥何暴挑口呦的拜\n",
      " - 不分开 海手的梦在海枯中状 谁是我们诗泪叠 邮寄会不觉缺 在蓝全看的味望 默持等待的道像 没有个待在乎底 \n",
      " - 我静静地了 在一起的昏 古没有人在意睛 干u的脸提 我找我的废写在西元前白深爱过世 是否玩的风市等待醒色 嘿\n",
      "epoch 180, perplexity 7.381416, time 0.51 sec\n",
      " - 分开始一种 如想盘雄 我们是那条龙 我右拳打开了天 化身为我不带宇 双让我们已经到 不会犯为 全生是你的\n",
      " - 不分开 听手的梦我 说在回忆 我想想能办法 北风的珊水海 我在刀暗很移 我爱悄人决个人 因身的你的想太 用\n",
      " - 我静静地 让我们乘的机会讯你紧等的片 我用第的特色 未来难预测 坚持当下的眼装 我说店安二 三两银够不够 景\n",
      "epoch 190, perplexity 6.802154, time 0.50 sec\n",
      " - 分开始一种 纷色英的人手 我爱你的指尖在西元前 深埋在美索不达米亚平原 几楔形话睡会有风难 随激完 只是\n",
      " - 不分开 海在我看诗摺咆哮辑也不想你 我睡古逼自 再开 豆腐 豆咿 弓箭 过发 从箭的白前 喜欢是我的中 跟\n",
      " - 我静静地 美多那感觉扯铃 这么刀后不知须来不能得及 想要一个人在斑驳 一些世界该狩猎 我永远地拆 我没形泪彻\n",
      "epoch 200, perplexity 6.603432, time 0.49 sec\n",
      " - 分开始 在我地盘这 梦就会听 为手在练 尖后的回没 让我们的天诺 放刚的爱好 我牵承悔 刻永世爱你的碑 \n",
      " - 不分开 海在我看上摺 他象你打手 梦没有不不够 景色入秋 漫天黄沙凉过 塞乡的客栈人多 牧草有没有 我马儿\n",
      " - 我静静地 美向哦人的规头 我又卑安静 三甩银够不够 景色入秋 漫天黄沙凉过不塞觉 都不是谁的眼校 我被谅旁的\n",
      "epoch 210, perplexity 6.354815, time 0.50 sec\n",
      " - 分开始 因为我示做奉陪 我一拳会营好下篷 没法泡化 不要放糊 就生 停脏 征战 弓箭 是失在飘中中面个望\n",
      " - 不分开 海我的手气 我已给的特子 你我难法不要 不要你在我忘了 断走 你的很角 微微己不到 不要没人不知 \n",
      " - 我静静地 美向的眼在 吹刺伤 回到我有谁的乾 一件页 画游放 啦儿了 你我跑 假远无 的灵不像去拍看 我想不\n",
      "epoch 220, perplexity 6.207609, time 0.51 sec\n",
      " - 分开始一种 等待英穿去 在虚拟进壤 music 有窗什么奇感雪 风在山路吹 雨往的画面上太 溃散你啜单上\n",
      " - 不分开 海在我在前暗 一开古的可亮 就算永不想这不界 没有我 一暗最中 我们和的爱情有样 什么兵器最喜欢 \n",
      " - 我静静地 美在那琵琶 蜕往分文 或逃哎m 我一定身北 有甚么资格 献世 即使 征战 弓忆 从忆的解去 你想很\n",
      "epoch 230, perplexity 5.831547, time 0.51 sec\n",
      " - 分开始不能 说了台的骄国 我也多的废子 未来难预测 坚持当下的选择 在我地盘这没你说得开不过 我要的感间\n",
      " - 不分开 海在我看之摺咆 一点在山子 那个蜡在等屉 对着真头 还有我再轻功回 一件疯酒孤棍棒的很头 只是我感\n",
      " - 我静静地 别向摆的风相 我也数的风 你舢全 走情马的地道 我们爱着我的於膀你看香直 回清自重 我们在努条龙 \n",
      "epoch 240, perplexity 5.766356, time 0.51 sec\n",
      " - 分开始 你们会舍渐 我在赶腰灵 每我形去无堡 咸应的时差 你们上的世样 天空 预测哭空 说大的世象 滴恶\n",
      " - 不分开 海我的喜式u定 神赏上正 不能在用时 说你的舞气u问 我却意的爱了 未来 我哈然飘 别生了解子 我\n",
      " - 我静静地 美紧摆的片晚 一把吉心 在远口 岸边的眼陵 崎嶇的蜡气 融明的手杖 焦化的手杖 看了傻的对 再意我\n",
      "epoch 250, perplexity 5.638040, time 0.50 sec\n",
      " - 分开始 你的身慢 失去被幅 让我们的假 一定 放手 功困 弓箭 升誉 从箭 升咿的眼季 喜欢的蜡杖 融化\n",
      " - 不分开 海在古旁看弹 却物让我的相悔 让傻麦染了 嘶吼不山太挡 随泪无睛 脱武黄人切棍 哼哼哈兮 快使用双\n",
      " - 我静静地 美在那人琶弹 接分用的时间 怎么隐后的解释 谁被远原的象征 谁被的父比 我将承悔世刻 将怎么灿 我\n",
      "epoch 260, perplexity 5.365331, time 0.51 sec\n",
      " - 分开始 在我地盘里 你就得听我的 把音乐收割 用听觉找哈乐 开始在雕刻 我个人的特色 未席难预测 坚持当\n",
      " - 不分开 海在我在前哭 远象的海飞 滴答滴 失蜡真 我哭了 微契一口 时了海的世 全一种味道 我想 伽蓝你 \n",
      " - 我静静地 美我的天式被写 透默的影 别开么了 不想要 爱你不再 如好一句 隔好你的时球 表 我坚該的大月 像\n",
      "epoch 270, perplexity 5.335155, time 0.51 sec\n",
      " - 分开始不能 一直肤色 我们著你不可对着生情 大著的城号 败失的手像 焦失的手杖 焦失的手像 焦失的手杖 \n",
      " - 不分开 海在台琵里的风楼 在人风忘了 进老别人在江南等我 泪不休 语沉默 娘子却依旧每日折去 在最风 穿梭\n",
      " - 我静静地变 我害不是让弃口 为什么龙让我开对 变的睫毛弯给二 我給头的爱不等样像什么抄人 我看不是闹弃自伤家\n",
      "epoch 280, perplexity 5.187440, time 0.51 sec\n",
      " - 分开始新 是一起热打的是斑很 因火熟悉 是我在你太上 动疯掉去 如果好双 走一生刮 让我们追求完美 看着\n",
      " - 不分开 海我的手片 你心上的世 你感全没有个诗 没有你 我是大 再继我到陪头f 你说我该多人堪 有些最太 \n",
      " - 我静静地 让我摆碎的阳方 看来纯方的象征 你被身向背 侧脸还够浪乐 因别人爱 角满她人 脑海 得急 作战的飘\n",
      "epoch 290, perplexity 5.036331, time 0.50 sec\n",
      " - 分开始 我们都去 再有心 我找狠 不要糖法坦白 我们将风哉了 只是我运越 有纸标进村悔 對妳的汉水 你我\n",
      " - 不分开 海在用色秋弹 进愿用e截量 丹亮倒鱼的蠢 戏向枯晶好法 是谁话的梦度 亲颜的总精事 我踏上风火轮 \n",
      " - 我静静地 让我摆记的阳方 雨头炮待的象征 然后还原的象 这一枯萎可来 是谁海的惩罚 把颜的总精事 我踏上风火\n",
      "epoch 300, perplexity 4.981743, time 0.52 sec\n",
      " - 分开始 你们不舍哭 我在全地间 每天年斗 我的感界 你已经不同 爱山埋珊瑚海 我表爱你拆封 你将头起 说\n",
      " - 不分开 海在黑琵河弹奏一曲东风破 岁月在墙上剥落看见回时候 犹了燃 简单动 啦边一百雷 o好多备下 我们的\n",
      " - 我静静地变 我一颗安北 离开有你的季节 方向盘远围恋笑 割弱我们相得有 一天海色的约定一股 不楠 消单门归枸\n"
     ]
    }
   ],
   "source": [
    "num_hiddens, num_steps = 256, 35\n",
    "num_epochs, batch_size, lr, clipping_theta = 300, 32, 100, 0.01\n",
    "pred_period, pred_len, prefixes = 10, 50, ['分开', '不分开', '我静静地']\n",
    "perplexities = train_and_predict_rnn_gluon(model, num_hiddens, vocab_size, ctx,\n",
    "                            corpus_indices, idx_to_char, char_to_idx,\n",
    "                            num_epochs, num_steps, lr, clipping_theta,\n",
    "                            batch_size, pred_period, pred_len, prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 231192,
     "status": "ok",
     "timestamp": 1582363606890,
     "user": {
      "displayName": "Zhibin Jiang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBtCQsggsYbhwo7wHg54VYCeP9aYN5gmmACw6tP=s64",
      "userId": "14703827957503696342"
     },
     "user_tz": -480
    },
    "id": "tEamh-tKKgnd",
    "outputId": "8686579b-ae37-4cff-d99a-c11f72ac4579"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2167.2273518627203,\n",
       " 514.4585204487433,\n",
       " 457.8852835246202,\n",
       " 420.7862561515121,\n",
       " 383.6545682777267,\n",
       " 364.0001782071033,\n",
       " 343.5226008965296,\n",
       " 328.82278618159575,\n",
       " 311.83496446161996,\n",
       " 297.02807612591255,\n",
       " 280.49930126415984,\n",
       " 267.01795807534313,\n",
       " 251.88793508749058,\n",
       " 239.4567273105404,\n",
       " 225.32562834593836,\n",
       " 214.1074965143991,\n",
       " 201.56094712420864,\n",
       " 191.8478823451365,\n",
       " 180.2680511928871,\n",
       " 170.34128430721054,\n",
       " 161.63030297139656,\n",
       " 152.27629063780228,\n",
       " 143.78831618339515,\n",
       " 136.47848126325633,\n",
       " 128.67948552373173,\n",
       " 121.8635101857824,\n",
       " 114.67635529679038,\n",
       " 108.4786249810788,\n",
       " 102.94673360006074,\n",
       " 97.56443789352444,\n",
       " 92.00525670630391,\n",
       " 87.49055426495383,\n",
       " 82.07857585383975,\n",
       " 78.59403105167628,\n",
       " 74.01850914776175,\n",
       " 71.5366791878533,\n",
       " 67.17857936204908,\n",
       " 63.81090131675539,\n",
       " 61.52943158808321,\n",
       " 58.274185760430285,\n",
       " 55.96988497320034,\n",
       " 53.58049011531275,\n",
       " 51.0634553433627,\n",
       " 49.10944349001716,\n",
       " 46.80599271383927,\n",
       " 44.91437242817392,\n",
       " 42.89524223209852,\n",
       " 41.97433381108114,\n",
       " 39.82842817075176,\n",
       " 38.2314626830309,\n",
       " 37.62669775068776,\n",
       " 36.1470619294148,\n",
       " 35.003989309508796,\n",
       " 33.285090130940624,\n",
       " 32.21406065229304,\n",
       " 31.567949282067442,\n",
       " 30.24477718689432,\n",
       " 29.79508301779332,\n",
       " 28.59506368998324,\n",
       " 27.734227122451966,\n",
       " 27.21567848841738,\n",
       " 26.653763295234576,\n",
       " 25.56924856918174,\n",
       " 25.25508042995054,\n",
       " 24.197162434207886,\n",
       " 23.88855708193922,\n",
       " 23.16892898881926,\n",
       " 22.72461576028965,\n",
       " 22.206998709185108,\n",
       " 21.510990957427637,\n",
       " 21.27989769544369,\n",
       " 20.72575831033994,\n",
       " 20.313504162641298,\n",
       " 19.936051157513607,\n",
       " 19.42238393721558,\n",
       " 19.089355529497933,\n",
       " 18.79001287733546,\n",
       " 18.11446986690369,\n",
       " 18.075968302101973,\n",
       " 17.616213976102056,\n",
       " 17.202930945708964,\n",
       " 17.079501302245173,\n",
       " 16.582844910594332,\n",
       " 16.461180153744035,\n",
       " 16.159368255880565,\n",
       " 15.68940082603498,\n",
       " 15.78641184277685,\n",
       " 15.337961057260037,\n",
       " 15.475249720950716,\n",
       " 14.986435752919688,\n",
       " 14.6824275982734,\n",
       " 14.278502703096693,\n",
       " 14.234039523276204,\n",
       " 14.230405069542046,\n",
       " 13.957421999526773,\n",
       " 13.526308125244292,\n",
       " 13.561043146587362,\n",
       " 13.346147256517249,\n",
       " 13.152452195890424,\n",
       " 12.942649074123162,\n",
       " 12.83073106209032,\n",
       " 12.862923974272837,\n",
       " 12.42630871702714,\n",
       " 12.188422022715914,\n",
       " 12.113803020419626,\n",
       " 12.016346704198057,\n",
       " 12.127197915087821,\n",
       " 11.681947636435547,\n",
       " 11.69530556042884,\n",
       " 11.570866683986045,\n",
       " 11.530227938953626,\n",
       " 11.482551850466207,\n",
       " 11.388227815614654,\n",
       " 11.230766767683148,\n",
       " 11.011889112500834,\n",
       " 10.853349924684466,\n",
       " 10.782504151892276,\n",
       " 10.75342845006827,\n",
       " 10.581258978580465,\n",
       " 10.496596705207786,\n",
       " 10.30391984850587,\n",
       " 10.27301776721679,\n",
       " 10.133629490578372,\n",
       " 10.119411426016608,\n",
       " 9.996142866000735,\n",
       " 10.051014640532921,\n",
       " 9.858778232848653,\n",
       " 9.779183818678662,\n",
       " 9.633412164796082,\n",
       " 9.426066009343671,\n",
       " 9.443362933860758,\n",
       " 9.416906915874074,\n",
       " 9.358713510456129,\n",
       " 9.31432021105876,\n",
       " 9.370427487055686,\n",
       " 9.12369488651853,\n",
       " 9.070199585040777,\n",
       " 8.969231952629194,\n",
       " 8.959396481725936,\n",
       " 8.959684625019838,\n",
       " 8.879716812975396,\n",
       " 8.696961687835284,\n",
       " 8.71237122654121,\n",
       " 8.719735695121026,\n",
       " 8.52748227450744,\n",
       " 8.45928850125064,\n",
       " 8.55067631957706,\n",
       " 8.547660368499379,\n",
       " 8.362944567401014,\n",
       " 8.311823195369783,\n",
       " 8.119068228473516,\n",
       " 8.225741976532282,\n",
       " 8.243355834337162,\n",
       " 8.071451968203563,\n",
       " 8.126040224363114,\n",
       " 7.947806079158854,\n",
       " 8.03301892085924,\n",
       " 7.831195064288848,\n",
       " 7.867238419875592,\n",
       " 7.915924686168913,\n",
       " 7.812107129021474,\n",
       " 7.847804812068991,\n",
       " 7.71047835874061,\n",
       " 7.582231534898245,\n",
       " 7.472082162749716,\n",
       " 7.465827209103507,\n",
       " 7.526034600986245,\n",
       " 7.5199748097062935,\n",
       " 7.325203810766399,\n",
       " 7.423663208221598,\n",
       " 7.344131272922141,\n",
       " 7.362813999711069,\n",
       " 7.27658990921156,\n",
       " 7.219315673447218,\n",
       " 7.330122934687407,\n",
       " 7.161795036515126,\n",
       " 7.100897806925456,\n",
       " 7.190755485704367,\n",
       " 7.04662694212493,\n",
       " 7.07992767984665,\n",
       " 7.027438999322652,\n",
       " 6.961012042566678,\n",
       " 7.10121843492422,\n",
       " 6.897713644897903,\n",
       " 6.895341351022965,\n",
       " 6.894247056996583,\n",
       " 6.925768786536755,\n",
       " 6.787574640979833,\n",
       " 6.863077849051958,\n",
       " 6.869061792922089,\n",
       " 6.828629070032869,\n",
       " 6.695414032144957,\n",
       " 6.661125543430673,\n",
       " 6.655827550452732,\n",
       " 6.610808651852935,\n",
       " 6.581256588168446,\n",
       " 6.655462839337643,\n",
       " 6.564260906814347,\n",
       " 6.576744294961628,\n",
       " 6.544294965047506,\n",
       " 6.392715767337338,\n",
       " 6.305999794699754,\n",
       " 6.390298131427277,\n",
       " 6.43589529105483,\n",
       " 6.438555940871573,\n",
       " 6.394770793687898,\n",
       " 6.382018335383757,\n",
       " 6.288383210935836,\n",
       " 6.173729663373233,\n",
       " 6.264386249691183,\n",
       " 6.249162353361717,\n",
       " 6.1917898963072355,\n",
       " 6.220738136245594,\n",
       " 6.312233831201777,\n",
       " 6.170961406419151,\n",
       " 6.117327018658366,\n",
       " 6.111449407315244,\n",
       " 6.0268514995570275,\n",
       " 6.095668875996041,\n",
       " 6.118466758024,\n",
       " 5.93560345811654,\n",
       " 5.984577328560393,\n",
       " 6.000746955932201,\n",
       " 5.937654389378152,\n",
       " 5.942114489832533,\n",
       " 5.8394694647191985,\n",
       " 5.813619565853859,\n",
       " 5.783511983144129,\n",
       " 5.8093826950022285,\n",
       " 5.77364695419576,\n",
       " 5.790629159246296,\n",
       " 5.817105404438949,\n",
       " 5.795682075894088,\n",
       " 5.756058356973648,\n",
       " 5.798500272685079,\n",
       " 5.720063700123323,\n",
       " 5.698766071965079,\n",
       " 5.699453870859469,\n",
       " 5.644201110704991,\n",
       " 5.659206479795392,\n",
       " 5.650577984545016,\n",
       " 5.605914477223665,\n",
       " 5.57993681024756,\n",
       " 5.54898242170978,\n",
       " 5.641442585575342,\n",
       " 5.566548703809633,\n",
       " 5.66420435724084,\n",
       " 5.668146628513258,\n",
       " 5.537937304817647,\n",
       " 5.53582508028353,\n",
       " 5.410188196876642,\n",
       " 5.483747633179725,\n",
       " 5.54026764353781,\n",
       " 5.5723807779651375,\n",
       " 5.529984160597403,\n",
       " 5.310151526256457,\n",
       " 5.379895605740297,\n",
       " 5.385183630776182,\n",
       " 5.285101210553379,\n",
       " 5.3334402657345885,\n",
       " 5.445189826610179,\n",
       " 5.317663155065428,\n",
       " 5.334636516398798,\n",
       " 5.311901825534111,\n",
       " 5.130930801166457,\n",
       " 5.2761523813282025,\n",
       " 5.268614200325478,\n",
       " 5.258404176164679,\n",
       " 5.185538547120082,\n",
       " 5.235849433273709,\n",
       " 5.234230471496167,\n",
       " 5.230184860050276,\n",
       " 5.139839279293306,\n",
       " 5.145299410142675,\n",
       " 5.069599443975884,\n",
       " 5.123757930317344,\n",
       " 5.047826790427539,\n",
       " 5.024842367945641,\n",
       " 5.06103085254219,\n",
       " 5.055139708359435,\n",
       " 5.000310808585071,\n",
       " 5.008396709253292,\n",
       " 5.045911309159628,\n",
       " 5.09975187351608,\n",
       " 5.14653761349663,\n",
       " 5.1392004449801,\n",
       " 4.964881332077103,\n",
       " 4.937619763499282,\n",
       " 4.90461362331007,\n",
       " 4.903505299471745,\n",
       " 4.873551515519408,\n",
       " 4.821358377864356,\n",
       " 4.961710567381697,\n",
       " 4.881559792086892,\n",
       " 4.9009340467347515,\n",
       " 4.884682830491128,\n",
       " 4.87002558011768,\n",
       " 4.845782693138275,\n",
       " 4.8386316735022135,\n",
       " 4.817281702676461]"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexities"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "lecture_6_Gluon_and_RNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
