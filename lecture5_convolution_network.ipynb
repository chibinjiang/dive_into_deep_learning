{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 卷积网络\n",
    "- 卷积网络\n",
    "- 互相关运算\n",
    "- 卷积核/过滤器, 不一定是正方形\n",
    "- 卷积窗口\n",
    "- 训练: 迭代卷积核和偏差\n",
    "- 如何通过数据学习卷积核:\n",
    "    - 使用gluon自带的Conv2D\n",
    "        - 参数: \n",
    "            - 通道数\n",
    "            - 核形状\n",
    "        - 二维卷积层使用4维输入输出，格式为(样本, 通道, 高, 宽): conv2d((samples, channels, height, width))\n",
    "    - 初始化成数组\n",
    "    - 计算 损失函数的梯度来更新权重和偏差\n",
    "- 特征图, feature map: 二维卷积层 的输出 可以看做是输入在空间维度(宽和高)上的某一级的表征\n",
    "- 感受野, receptive field: 影响 元素x的前向计算的所有可能输入区域(可能会超出输入区域) -> 二维的八个方位\n",
    "    - 可以通过更深的卷积神经网络使特征图中单个元素的感受野变得更加广阔，从而捕捉输入上更大尺寸的特征\n",
    "    - 比如 X_3*3 -(K1_2*2)-> Y_2*2 -(K2_2*2)-> Z_1*1,  Z在Y上的感受野是Y的全部4个元素, 而在输入(X)上的感受野是输入的全部9个元素\n",
    "- 怎么设计卷积核, 令其能够检测出边缘:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet.gluon import nn\n",
    "from mxnet import autograd, nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d(X, K):\n",
    "    \"\"\"\n",
    "    too slow\n",
    "    X: input\n",
    "    K: kernel\n",
    "    \"\"\"\n",
    "    h, w = K.shape\n",
    "    Y = nd.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i, j] = (X[i: i + h, j: j + w] * K).sum()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = nd.random.uniform(shape=(100, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = nd.ones(shape=(2, 2)) * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[0.5488135  0.5928446  0.71518934 ... 0.45720482 0.55868983 0.43069857]\n",
       " [0.14038694 0.9391278  0.19810149 ... 0.12132858 0.5108276  0.5693113 ]\n",
       " [0.89294696 0.43706194 0.8962931  ... 0.01902474 0.9489773  0.03978036]\n",
       " ...\n",
       " [0.9162014  0.44308117 0.59071505 ... 0.5811341  0.05543189 0.99660516]\n",
       " [0.49628252 0.6452971  0.80752385 ... 0.9595277  0.6766825  0.50212663]\n",
       " [0.6899407  0.47096756 0.13747388 ... 0.6698337  0.7846096  0.26094997]]\n",
       "<NDArray 100x100 @cpu(0)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.44234568"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.5488135 * 2 + 0.5928446 * 2 + 0.14038694 * 2 + 0.9391278 * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.25 s, sys: 190 ms, total: 2.44 s\n",
      "Wall time: 2.13 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "[[4.4423456 4.8905263 5.071892  ... 2.5734859 3.2961016 4.139055 ]\n",
       " [4.8190475 4.941169  3.7830637 ... 1.7348094 3.2003164 4.137793 ]\n",
       " [6.1226377 6.289296  4.4553595 ... 3.1869245 3.990566  3.8759232]\n",
       " ...\n",
       " [6.3993626 4.4471655 3.894683  ... 3.9462676 4.67764   4.0472145]\n",
       " [5.0017242 4.973234  5.442731  ... 5.556615  4.5455523 4.4616923]\n",
       " [4.6049757 4.1225247 3.9016984 ... 6.3918395 6.181307  4.448737 ]]\n",
       "<NDArray 99x99 @cpu(0)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time corr2d(X, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2D(nn.Block):\n",
    "    \"\"\"\n",
    "    二维卷积层\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_shape, **kwargs):\n",
    "        \"\"\"\n",
    "        :param kernel_shape: tuple\n",
    "        \"\"\"\n",
    "        super(Conv2D, self).__init__(**kwargs)\n",
    "        self.weight = self.params.get(\"weight\", shape=kernel_shape)\n",
    "        self.bias = self.params.get(\"bias\", shape=(1, ))\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return corr2d(X, self.weight.data()) + self.bias.data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[0.11220663 0.1650652  0.09899607 ... 0.13774395 0.08986556 0.11184095]\n",
       " [0.10304052 0.1554206  0.13556352 ... 0.13074315 0.10483424 0.10050067]\n",
       " [0.17754516 0.11567509 0.13443696 ... 0.06925815 0.1603241  0.06498009]\n",
       " ...\n",
       " [0.13761944 0.16539177 0.0734662  ... 0.12492651 0.09096377 0.13385639]\n",
       " [0.1245357  0.13291404 0.14092755 ... 0.1288637  0.13798285 0.07410178]\n",
       " [0.13239706 0.12881969 0.17085703 ... 0.10291093 0.10774222 0.19160858]]\n",
       "<NDArray 98x98 @cpu(0)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d = Conv2D((3,3))\n",
    "conv2d.initialize()\n",
    "conv2d(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 0.01637076 -0.01589154  0.06212472]\n",
       " [ 0.05636378  0.02545484 -0.007007  ]\n",
       " [-0.0196689   0.01582889 -0.00881553]]\n",
       "<NDArray 3x3 @cpu(0)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d.weight.data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[0.0563288]\n",
       "<NDArray 1 @cpu(0)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d.bias.data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 检测图片中物体的边缘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[1. 1. 0. 0. 0. 0. 1. 1.]\n",
       " [1. 1. 0. 0. 0. 0. 1. 1.]\n",
       " [1. 1. 0. 0. 0. 0. 1. 1.]\n",
       " [1. 1. 0. 0. 0. 0. 1. 1.]\n",
       " [1. 1. 0. 0. 0. 0. 1. 1.]\n",
       " [1. 1. 0. 0. 0. 0. 1. 1.]]\n",
       "<NDArray 6x8 @cpu(0)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = nd.ones((6, 8))\n",
    "images[:, 2:6] = 0\n",
    "images\n",
    "# 从白到黑, 又从黑到白, 两条分界线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 1. -1.]]\n",
       "<NDArray 1x2 @cpu(0)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = nd.array([[1, -1]])\n",
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_edge = corr2d(images, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 0.  1.  0.  0.  0. -1.  0.]\n",
       " [ 0.  1.  0.  0.  0. -1.  0.]\n",
       " [ 0.  1.  0.  0.  0. -1.  0.]\n",
       " [ 0.  1.  0.  0.  0. -1.  0.]\n",
       " [ 0.  1.  0.  0.  0. -1.  0.]\n",
       " [ 0.  1.  0.  0.  0. -1.  0.]]\n",
       "<NDArray 6x7 @cpu(0)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_edge\n",
    "# 检测出 黑到白的分界线: 1\n",
    "# 检测出 白到黑的分极限: -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_net():\n",
    "    conv2d = nn.Conv2D(1, kernel_size=(1, 2))\n",
    "    conv2d.initialize()       \n",
    "    return conv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 二维卷积层使用4维输入输出，格式为(样本, 通道, 高, 宽)，这里批量大小（批量中的样本数）和通道数均为1\n",
    "def train_cnn(net, features, labels):\n",
    "    for i in range(10):\n",
    "        with autograd.record():\n",
    "            Y_hat = net(features)\n",
    "            l = (Y_hat - labels) ** 2\n",
    "        l.backward()\n",
    "        # 简单起见，这里忽略了偏差\n",
    "        # conv2d.weight.data()[:] -= 3e-2 * conv2d.weight.grad()\n",
    "        net.weight.set_data(net.weight.data() - 3e-2 * net.weight.grad())\n",
    "        if (i + 1) % 2 == 0:\n",
    "            print('batch %d, loss %.3f' % (i + 1, l.sum().asscalar()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 2, loss 4.582\n",
      "batch 4, loss 0.770\n",
      "batch 6, loss 0.130\n",
      "batch 8, loss 0.022\n",
      "batch 10, loss 0.004\n"
     ]
    }
   ],
   "source": [
    "net = get_net()\n",
    "train_cnn(net, features=images.reshape((1, 1, 6, 8)), labels=images_edge.reshape((1, 1, 6, 7)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[1. 1. 0. 0. 0. 0. 1. 1.]\n",
       " [1. 1. 0. 0. 0. 0. 1. 1.]\n",
       " [1. 1. 0. 0. 0. 0. 1. 1.]\n",
       " [1. 1. 0. 0. 0. 0. 1. 1.]\n",
       " [1. 1. 0. 0. 0. 0. 1. 1.]\n",
       " [1. 1. 0. 0. 0. 0. 1. 1.]]\n",
       "<NDArray 6x8 @cpu(0)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 0.  1.  0.  0.  0. -1.  0.]\n",
       " [ 0.  1.  0.  0.  0. -1.  0.]\n",
       " [ 0.  1.  0.  0.  0. -1.  0.]\n",
       " [ 0.  1.  0.  0.  0. -1.  0.]\n",
       " [ 0.  1.  0.  0.  0. -1.  0.]\n",
       " [ 0.  1.  0.  0.  0. -1.  0.]]\n",
       "<NDArray 6x7 @cpu(0)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[[[ 0.02766836 -0.05610075]]]]\n",
       "<NDArray 1x1x1x2 @cpu(0)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.weight.set_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[0.]\n",
       "<NDArray 1 @cpu(0)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.bias.data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 练习\n",
    "1. 构造一个输入图像X，令它有水平方向的边缘。如何设计卷积核K来检测图像中水平边缘? 如果是对角方向的边缘呢?\n",
    "2. 试着对我们自己构造的Conv2D类进行自动求梯度，会有什么样的错误信息？在该类的forward函数里，将corr2d函数替换成nd.Convolution类使得自动求梯度变得可行。\n",
    "    - 对一个for循环如何求梯度\n",
    "3. 如何通过变化输入和核数组将互相关运算表示成一个矩阵乘法？\n",
    "4. 如何构造一个全连接层来进行物体边缘检测？\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
